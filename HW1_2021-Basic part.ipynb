{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Choose a long text (a novel), do preprocessing on it (delete punctuation, lemmatize it, make sure that every sentence starts on a new line), don't forget to put the lemmatized text or a link to your lemmatized text into your hw folder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen \"Roadside picnic\"  by Arkadiy and Boris Strugackie. I have cut off the second part of the text, since lemmatization of the whole novel was problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import operator\n",
    "from string import punctuation\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import gensim\n",
    "import logging\n",
    "import nltk.data\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    words = ''\n",
    "    p = list(punctuation)\n",
    "    for i in range(len(s)):\n",
    "        if s[i] in p:\n",
    "            continue\n",
    "        words = words + s[i]\n",
    "    phrase = str(words)\n",
    "    spltd = phrase.split()\n",
    "    return spltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('strugackie_preproc_1.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text.splitlines() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below I augment a string containing a part of speech of the word analysed to the string representing lemma. This decision is driven by the need to сarry out agreement in task 5. A more detailed explanation of the techniques is given before the code for task 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines2= []\n",
    "for l in lines:\n",
    "    line = ' '.join(tokenize(l))\n",
    "    lemmas = m.lemmatize(line)\n",
    "    lemmas2 = []\n",
    "    for l in lemmas:\n",
    "        l_ana = morph.parse(l)[0]\n",
    "        POS = str(l_ana.tag.POS)\n",
    "        l_new = l+ '_' + POS\n",
    "        if l_new == ' _None':\n",
    "            pass\n",
    "        else:\n",
    "            lemmas2.append(l_new)\n",
    "    line2 = ' '.join(lemmas2)\n",
    "    lines2.append(line2)\n",
    "tex2 = '\\n'.join(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(\"strugackie2.txt\", \"w+\")\n",
    "my_file.write(tex2)\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Train a word2vec model on the chosen text, set the parameters (window size, vector size, number of iterations etc.), comment on your choice of parameter settings and the reasoning behind it, experiment with the settings and show me that you have chosen the settings after some experimentation and consideration -- 2 points**\n",
    "\n",
    "**3.Test your model, use most_similar, similarity, doesnt_match functions, comment on the model performance, explain the reasoning behind the testing -- 2 points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'strugackie2.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us implement the following paramaters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 17:57:31,484 : INFO : collecting all words and their counts\n",
      "2021-09-21 17:57:31,495 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-21 17:57:31,530 : INFO : collected 4182 word types from a corpus of 21762 raw words and 2531 sentences\n",
      "2021-09-21 17:57:31,532 : INFO : Creating a fresh vocabulary\n",
      "2021-09-21 17:57:31,556 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1891 unique words (45.21759923481588%% of original 4182, drops 2291)', 'datetime': '2021-09-21T17:57:31.556443', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:57:31,559 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 19471 word corpus (89.47247495634592%% of original 21762, drops 2291)', 'datetime': '2021-09-21T17:57:31.559754', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:57:31,591 : INFO : deleting the raw counts dictionary of 4182 items\n",
      "2021-09-21 17:57:31,593 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2021-09-21 17:57:31,595 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 14540.499420536875 word corpus (74.7%% of prior 19471)', 'datetime': '2021-09-21T17:57:31.595573', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:57:31,662 : INFO : estimated required memory for 1891 words and 300 dimensions: 5483900 bytes\n",
      "2021-09-21 17:57:31,664 : INFO : resetting layer weights\n",
      "2021-09-21 17:57:31,675 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-21T17:57:31.675317', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-09-21 17:57:31,677 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1891 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=15 shrink_windows=True', 'datetime': '2021-09-21T17:57:31.677317', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:57:31,739 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:57:31,755 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:57:31,768 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:57:31,770 : INFO : EPOCH - 1 : training on 21762 raw words (14501 effective words) took 0.1s, 176730 effective words/s\n",
      "2021-09-21 17:57:31,840 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:57:31,846 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:57:31,867 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:57:31,870 : INFO : EPOCH - 2 : training on 21762 raw words (14481 effective words) took 0.1s, 161514 effective words/s\n",
      "2021-09-21 17:57:31,925 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:57:31,949 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:57:31,955 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:57:31,957 : INFO : EPOCH - 3 : training on 21762 raw words (14593 effective words) took 0.1s, 187631 effective words/s\n",
      "2021-09-21 17:57:32,028 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:57:32,032 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:57:32,054 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:57:32,056 : INFO : EPOCH - 4 : training on 21762 raw words (14558 effective words) took 0.1s, 162341 effective words/s\n",
      "2021-09-21 17:57:32,127 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:57:32,132 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:57:32,157 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:57:32,158 : INFO : EPOCH - 5 : training on 21762 raw words (14557 effective words) took 0.1s, 158421 effective words/s\n",
      "2021-09-21 17:57:32,160 : INFO : Word2Vec lifecycle event {'msg': 'training on 108810 raw words (72690 effective words) took 0.5s, 150928 effective words/s', 'datetime': '2021-09-21T17:57:32.160496', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:57:32,161 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1891, vector_size=300, alpha=0.025)', 'datetime': '2021-09-21T17:57:32.161495', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_strugackie1 = gensim.models.Word2Vec(data, vector_size=300, window=15, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    }
   ],
   "source": [
    "print(len(model_strugackie1.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test my model, I formulated several hypotheses:\n",
    "1. If a model is good enough, it should provide reasonable results for a query aiming at identifying words which describe Redrik (рэдрик_NOUN) as a person, but not as a stalker (сталкер_NOUN).\n",
    "2. If a model is good enough, it should provide reasonable results for a query seeking words that can be representative of Redrik as a character in general.\n",
    "3. If a model is good enough, it should predict vectors for рэрик_NOUN and гута_NOUN, as well as рэдрик_NOUN and кирилл_NOUN to show a higher similarity coefficient than vectors for гута_NOUN and кирилл_NOUN, sincee characters of Guta and Kirill do not occur in the same scene in the novel.\n",
    "4. If a model is good enough, it should be able to identify мартышка_NOUN as an odd one out in the list of рэдрик_NOUN зона_NOUN барбридж_NOUN кирилл_NOUN, as the character of Martyshka does not visit Zona in the original story.\n",
    "I will use functions `most_similar`, `similarity`, `doesnt_match` specified in the task, to check if the outlined above hyposes hold for each model.\n",
    "\n",
    "\n",
    "Further on, I will only comment on the cases where a models seems not to provide a satisfactory result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('протез_NOUN', 0.08394461870193481),\n",
       " ('вырез_NOUN', 0.06946960836648941),\n",
       " ('верный_ADJF', 0.06739284098148346)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie1.wv.most_similar(positive=[\"рэдрик_NOUN\"], negative=[\"сталкер_NOUN\"], topn=3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и_CONJ', 0.9999586939811707),\n",
       " ('на_PREP', 0.9999536871910095),\n",
       " ('с_PREP', 0.9999494552612305)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie1.wv.most_similar(positive=[\"рэдрик_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the result above, the present model fails to provide satisfactory list of terms describing Redrik as a character. The resulting terms are simply the most frequent ones in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998583"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie1.wv.similarity(\"рэдрик_NOUN\", \"гута_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99983233"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie1.wv.similarity(\"рэдрик_NOUN\", \"кирилл_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997754"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie1.wv.similarity(\"кирилл_NOUN\", \"гута_NOUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity coefficients are pretty similar for all the three pairs compaired. This can be either because the model is weak, or the original hypothesis is plain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мартышка_NOUN'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie1.wv.doesnt_match(\"рэдрик_NOUN зона_NOUN барбридж_NOUN кирилл_NOUN мартышка_NOUN\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us increase the number of trainings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 17:58:05,627 : INFO : collecting all words and their counts\n",
      "2021-09-21 17:58:05,630 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-21 17:58:05,677 : INFO : collected 4182 word types from a corpus of 21762 raw words and 2531 sentences\n",
      "2021-09-21 17:58:05,679 : INFO : Creating a fresh vocabulary\n",
      "2021-09-21 17:58:05,711 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1891 unique words (45.21759923481588%% of original 4182, drops 2291)', 'datetime': '2021-09-21T17:58:05.711203', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:58:05,713 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 19471 word corpus (89.47247495634592%% of original 21762, drops 2291)', 'datetime': '2021-09-21T17:58:05.712203', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:58:05,755 : INFO : deleting the raw counts dictionary of 4182 items\n",
      "2021-09-21 17:58:05,756 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2021-09-21 17:58:05,758 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 14540.499420536875 word corpus (74.7%% of prior 19471)', 'datetime': '2021-09-21T17:58:05.758832', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:58:05,843 : INFO : estimated required memory for 1891 words and 300 dimensions: 5483900 bytes\n",
      "2021-09-21 17:58:05,845 : INFO : resetting layer weights\n",
      "2021-09-21 17:58:05,855 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-21T17:58:05.855633', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-09-21 17:58:05,857 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1891 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=15 shrink_windows=True', 'datetime': '2021-09-21T17:58:05.857550', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:58:05,918 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:58:05,924 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:58:05,938 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:58:05,940 : INFO : EPOCH - 1 : training on 21762 raw words (14501 effective words) took 0.1s, 209338 effective words/s\n",
      "2021-09-21 17:58:05,993 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:58:05,999 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:58:06,020 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:58:06,023 : INFO : EPOCH - 2 : training on 21762 raw words (14481 effective words) took 0.1s, 191741 effective words/s\n",
      "2021-09-21 17:58:06,084 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:58:06,087 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:58:06,109 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:58:06,112 : INFO : EPOCH - 3 : training on 21762 raw words (14593 effective words) took 0.1s, 180267 effective words/s\n",
      "2021-09-21 17:58:06,114 : INFO : Word2Vec lifecycle event {'msg': 'training on 65286 raw words (43575 effective words) took 0.3s, 170810 effective words/s', 'datetime': '2021-09-21T17:58:06.114489', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:58:06,116 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1891, vector_size=300, alpha=0.025)', 'datetime': '2021-09-21T17:58:06.116049', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_strugackie2 = gensim.models.Word2Vec(data, vector_size=300, window=15, min_count=2, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    }
   ],
   "source": [
    "print(len(model_strugackie2.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('востроносый_ADJF', 0.12317244708538055),\n",
       " ('выдерживать_INFN', 0.1169157326221466),\n",
       " ('досада_NOUN', 0.11178231984376907)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie2.wv.most_similar(positive=[\"рэдрик_NOUN\"], negative=[\"сталкер_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и_CONJ', 0.999818742275238),\n",
       " ('на_PREP', 0.9998012185096741),\n",
       " ('в_PREP', 0.9997910857200623)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie2.wv.most_similar(positive=[\"рэдрик_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the result, increasing the number of trainings 3 times on it's own does not solve the problem of the most frequent tokens. It worth mentioning that introducing a \"stopwords\" module would help, however since I have all tokens in my model with an augmented \"part of speech\" string, this will not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99926007"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie2.wv.similarity(\"рэдрик_NOUN\", \"гута_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994021"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie2.wv.similarity(\"рэдрик_NOUN\", \"кирилл_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99905694"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie2.wv.similarity(\"кирилл_NOUN\", \"гута_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мартышка_NOUN'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie2.wv.doesnt_match(\"рэдрик_NOUN зона_NOUN барбридж_NOUN кирилл_NOUN мартышка_NOUN\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the second model was not better than the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the third model, I will preserve all the paramaters as they were specified above, but the query window will be reduced to 5 to tackle the \"most frequent words\" problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-24 10:59:31,877 : INFO : collecting all words and their counts\n",
      "2021-09-24 10:59:31,922 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-24 10:59:31,962 : INFO : collected 4182 word types from a corpus of 21762 raw words and 2531 sentences\n",
      "2021-09-24 10:59:31,962 : INFO : Creating a fresh vocabulary\n",
      "2021-09-24 10:59:31,993 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1891 unique words (45.21759923481588%% of original 4182, drops 2291)', 'datetime': '2021-09-24T10:59:31.984013', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-24 10:59:31,994 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 19471 word corpus (89.47247495634592%% of original 21762, drops 2291)', 'datetime': '2021-09-24T10:59:31.994354', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-24 10:59:32,022 : INFO : deleting the raw counts dictionary of 4182 items\n",
      "2021-09-24 10:59:32,022 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2021-09-24 10:59:32,038 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 14540.499420536875 word corpus (74.7%% of prior 19471)', 'datetime': '2021-09-24T10:59:32.038677', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-24 10:59:32,082 : INFO : estimated required memory for 1891 words and 300 dimensions: 5483900 bytes\n",
      "2021-09-24 10:59:32,082 : INFO : resetting layer weights\n",
      "2021-09-24 10:59:32,089 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-24T10:59:32.089981', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-09-24 10:59:32,106 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1891 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-09-24T10:59:32.106852', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-24 10:59:33,186 : INFO : EPOCH 1 - PROGRESS: at 7.70% examples, 1165 words/s, in_qsize 2, out_qsize 1\n",
      "2021-09-24 10:59:33,186 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-24 10:59:33,186 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-24 10:59:33,203 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-24 10:59:33,203 : INFO : EPOCH - 1 : training on 21762 raw words (14554 effective words) took 1.0s, 14042 effective words/s\n",
      "2021-09-24 10:59:33,232 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-24 10:59:33,249 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-24 10:59:33,249 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-24 10:59:33,249 : INFO : EPOCH - 2 : training on 21762 raw words (14525 effective words) took 0.0s, 318830 effective words/s\n",
      "2021-09-24 10:59:33,281 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-24 10:59:33,281 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-24 10:59:33,298 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-24 10:59:33,298 : INFO : EPOCH - 3 : training on 21762 raw words (14498 effective words) took 0.0s, 350834 effective words/s\n",
      "2021-09-24 10:59:33,298 : INFO : Word2Vec lifecycle event {'msg': 'training on 65286 raw words (43577 effective words) took 1.2s, 36502 effective words/s', 'datetime': '2021-09-24T10:59:33.298030', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-24 10:59:33,298 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1891, vector_size=300, alpha=0.025)', 'datetime': '2021-09-24T10:59:33.298030', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_strugackie3 = gensim.models.Word2Vec(data, vector_size=300, window=5, min_count=2, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    }
   ],
   "source": [
    "print(len(model_strugackie3.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('досада_NOUN', 0.19106616079807281),\n",
       " ('востроносый_ADJF', 0.1660316288471222),\n",
       " ('бугор_NOUN', 0.16057683527469635)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie3.wv.most_similar(positive=[\"рэдрик_NOUN\"], negative=[\"сталкер_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и_CONJ', 0.9983274340629578),\n",
       " ('на_PREP', 0.9982181191444397),\n",
       " ('он_NPRO', 0.997957170009613)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie3.wv.most_similar(positive=[\"рэдрик_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the result obtained, reducing the window size only did not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99207306"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie3.wv.similarity(\"рэдрик_NOUN\", \"гута_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950063"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie3.wv.similarity(\"рэдрик_NOUN\", \"кирилл_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907466"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie3.wv.similarity(\"кирилл_NOUN\", \"гута_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мартышка_NOUN'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie3.wv.doesnt_match(\"рэдрик_NOUN зона_NOUN барбридж_NOUN кирилл_NOUN мартышка_NOUN\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now consider a model that uses the skip-gram algorithm (all the other paramentes are keeped as they were specified above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 17:59:25,831 : INFO : collecting all words and their counts\n",
      "2021-09-21 17:59:25,834 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-21 17:59:25,873 : INFO : collected 4182 word types from a corpus of 21762 raw words and 2531 sentences\n",
      "2021-09-21 17:59:25,877 : INFO : Creating a fresh vocabulary\n",
      "2021-09-21 17:59:25,897 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1891 unique words (45.21759923481588%% of original 4182, drops 2291)', 'datetime': '2021-09-21T17:59:25.897292', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:59:25,898 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 19471 word corpus (89.47247495634592%% of original 21762, drops 2291)', 'datetime': '2021-09-21T17:59:25.898292', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:59:25,931 : INFO : deleting the raw counts dictionary of 4182 items\n",
      "2021-09-21 17:59:25,933 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2021-09-21 17:59:25,935 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 14540.499420536875 word corpus (74.7%% of prior 19471)', 'datetime': '2021-09-21T17:59:25.934072', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:59:26,006 : INFO : estimated required memory for 1891 words and 300 dimensions: 5483900 bytes\n",
      "2021-09-21 17:59:26,010 : INFO : resetting layer weights\n",
      "2021-09-21 17:59:26,018 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-21T17:59:26.018215', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-09-21 17:59:26,021 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1891 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-09-21T17:59:26.021649', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:59:26,105 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:26,155 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:26,173 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:26,175 : INFO : EPOCH - 1 : training on 21762 raw words (14554 effective words) took 0.1s, 100994 effective words/s\n",
      "2021-09-21 17:59:26,243 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:26,334 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:26,338 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:26,339 : INFO : EPOCH - 2 : training on 21762 raw words (14514 effective words) took 0.2s, 93081 effective words/s\n",
      "2021-09-21 17:59:26,423 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:26,482 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:26,490 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:26,492 : INFO : EPOCH - 3 : training on 21762 raw words (14511 effective words) took 0.1s, 101915 effective words/s\n",
      "2021-09-21 17:59:26,494 : INFO : Word2Vec lifecycle event {'msg': 'training on 65286 raw words (43579 effective words) took 0.5s, 92628 effective words/s', 'datetime': '2021-09-21T17:59:26.494769', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:59:26,495 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1891, vector_size=300, alpha=0.025)', 'datetime': '2021-09-21T17:59:26.495769', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_strugackie4 = gensim.models.Word2Vec(data, vector_size=300, window=5, min_count=2, sg= 1, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    }
   ],
   "source": [
    "print(len(model_strugackie4.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('отель_NOUN', 0.09701748192310333),\n",
       " ('вне_PREP', 0.05859766900539398),\n",
       " ('верный_ADJF', 0.058121826499700546)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie4.wv.most_similar(positive=[\"рэдрик_NOUN\"], negative=[\"сталкер_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('два_NUMR', 0.9995715022087097),\n",
       " ('с_PREP', 0.9995636940002441),\n",
       " ('барбридж_NOUN', 0.9995586276054382)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie4.wv.most_similar(positive=[\"рэдрик_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, skip-gram model shows a better performind in the similarity test that the \"bag of words\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99937505"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie4.wv.similarity(\"рэдрик_NOUN\", \"гута_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99934775"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie4.wv.similarity(\"рэдрик_NOUN\", \"кирилл_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993142"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie4.wv.similarity(\"кирилл_NOUN\", \"гута_NOUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, none of the models studied so far gave a predicted result in the test above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мартышка_NOUN'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie4.wv.doesnt_match(\"рэдрик_NOUN зона_NOUN барбридж_NOUN кирилл_NOUN мартышка_NOUN\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us go back to the \"bag of words\" model and increase the number of epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 17:59:48,994 : INFO : collecting all words and their counts\n",
      "2021-09-21 17:59:48,997 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-21 17:59:49,037 : INFO : collected 4182 word types from a corpus of 21762 raw words and 2531 sentences\n",
      "2021-09-21 17:59:49,039 : INFO : Creating a fresh vocabulary\n",
      "2021-09-21 17:59:49,061 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1891 unique words (45.21759923481588%% of original 4182, drops 2291)', 'datetime': '2021-09-21T17:59:49.061902', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:59:49,062 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 19471 word corpus (89.47247495634592%% of original 21762, drops 2291)', 'datetime': '2021-09-21T17:59:49.062897', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:59:49,094 : INFO : deleting the raw counts dictionary of 4182 items\n",
      "2021-09-21 17:59:49,095 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2021-09-21 17:59:49,098 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 14540.499420536875 word corpus (74.7%% of prior 19471)', 'datetime': '2021-09-21T17:59:49.098642', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:59:49,176 : INFO : estimated required memory for 1891 words and 300 dimensions: 5483900 bytes\n",
      "2021-09-21 17:59:49,179 : INFO : resetting layer weights\n",
      "2021-09-21 17:59:49,186 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-21T17:59:49.186006', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-09-21 17:59:49,188 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1891 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-09-21T17:59:49.188023', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:59:49,261 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,264 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,283 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,285 : INFO : EPOCH - 1 : training on 21762 raw words (14554 effective words) took 0.1s, 166911 effective words/s\n",
      "2021-09-21 17:59:49,348 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,352 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,370 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,371 : INFO : EPOCH - 2 : training on 21762 raw words (14514 effective words) took 0.1s, 190433 effective words/s\n",
      "2021-09-21 17:59:49,435 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,454 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,456 : INFO : EPOCH - 3 : training on 21762 raw words (14511 effective words) took 0.1s, 193743 effective words/s\n",
      "2021-09-21 17:59:49,513 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,515 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,533 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,534 : INFO : EPOCH - 4 : training on 21762 raw words (14575 effective words) took 0.1s, 212913 effective words/s\n",
      "2021-09-21 17:59:49,598 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,600 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,618 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,620 : INFO : EPOCH - 5 : training on 21762 raw words (14555 effective words) took 0.1s, 189401 effective words/s\n",
      "2021-09-21 17:59:49,688 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,713 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,714 : INFO : EPOCH - 6 : training on 21762 raw words (14584 effective words) took 0.1s, 169757 effective words/s\n",
      "2021-09-21 17:59:49,772 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,778 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,800 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,804 : INFO : EPOCH - 7 : training on 21762 raw words (14535 effective words) took 0.1s, 183761 effective words/s\n",
      "2021-09-21 17:59:49,871 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,874 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,893 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,896 : INFO : EPOCH - 8 : training on 21762 raw words (14555 effective words) took 0.1s, 179532 effective words/s\n",
      "2021-09-21 17:59:49,967 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,969 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,990 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,992 : INFO : EPOCH - 9 : training on 21762 raw words (14540 effective words) took 0.1s, 168416 effective words/s\n",
      "2021-09-21 17:59:50,065 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:50,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:50,091 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:50,095 : INFO : EPOCH - 10 : training on 21762 raw words (14482 effective words) took 0.1s, 159746 effective words/s\n",
      "2021-09-21 17:59:50,163 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:50,169 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:50,192 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:50,196 : INFO : EPOCH - 11 : training on 21762 raw words (14491 effective words) took 0.1s, 158035 effective words/s\n",
      "2021-09-21 17:59:50,263 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:50,267 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:50,290 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:50,294 : INFO : EPOCH - 12 : training on 21762 raw words (14535 effective words) took 0.1s, 161543 effective words/s\n",
      "2021-09-21 17:59:50,356 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:50,363 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:50,387 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:50,388 : INFO : EPOCH - 13 : training on 21762 raw words (14544 effective words) took 0.1s, 170418 effective words/s\n",
      "2021-09-21 17:59:50,451 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:50,464 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:50,480 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:50,481 : INFO : EPOCH - 14 : training on 21762 raw words (14517 effective words) took 0.1s, 173360 effective words/s\n",
      "2021-09-21 17:59:50,546 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:50,550 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:50,571 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:50,572 : INFO : EPOCH - 15 : training on 21762 raw words (14498 effective words) took 0.1s, 169712 effective words/s\n",
      "2021-09-21 17:59:50,574 : INFO : Word2Vec lifecycle event {'msg': 'training on 326430 raw words (217990 effective words) took 1.4s, 157450 effective words/s', 'datetime': '2021-09-21T17:59:50.574170', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:59:50,575 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1891, vector_size=300, alpha=0.025)', 'datetime': '2021-09-21T17:59:50.575377', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_strugackie5 = gensim.models.Word2Vec(data, vector_size=300, window=5, min_count=2, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    }
   ],
   "source": [
    "print(len(model_strugackie5.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('протез_NOUN', 0.0407133586704731),\n",
       " ('новость_NOUN', 0.030972125008702278),\n",
       " ('врать_INFN', 0.029972020536661148)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.most_similar(positive=[\"рэдрик_NOUN\"], negative=[\"сталкер_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('барбридж_NOUN', 0.9998448491096497),\n",
       " ('хрипатый_ADJF', 0.9998412132263184),\n",
       " ('снова_ADVB', 0.9997943043708801)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.most_similar(positive=[\"рэдрик_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunatelly, the result of this model is better on this test than of any tried so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99977547"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.similarity(\"рэдрик_NOUN\", \"гута_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99955827"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.similarity(\"рэдрик_NOUN\", \"кирилл_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996924"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.similarity(\"кирилл_NOUN\", \"гута_NOUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, it cannot find the expected distinction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since both Dina and Martyshka have not visited Zona on their own, but Martyshka is definitelly more connected to it, it is interesting to check which of this terms would stand out on the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'дина_NOUN'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.doesnt_match(\"рэдрик_NOUN зона_NOUN барбридж_NOUN кирилл_NOUN мартышка_NOUN дина_NOUN\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мартышка_NOUN'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.doesnt_match(\"рэдрик_NOUN зона_NOUN барбридж_NOUN кирилл_NOUN мартышка_NOUN\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us introduce a number of fake words and increase the number of trainings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 09:09:36,849 : INFO : collecting all words and their counts\n",
      "2021-09-22 09:09:36,885 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-22 09:09:36,901 : INFO : collected 4182 word types from a corpus of 21762 raw words and 2531 sentences\n",
      "2021-09-22 09:09:36,901 : INFO : Creating a fresh vocabulary\n",
      "2021-09-22 09:09:36,918 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 4182 unique words (100.0%% of original 4182, drops 0)', 'datetime': '2021-09-22T09:09:36.918030', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-22 09:09:36,918 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 21762 word corpus (100.0%% of original 21762, drops 0)', 'datetime': '2021-09-22T09:09:36.918030', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-22 09:09:36,968 : INFO : deleting the raw counts dictionary of 4182 items\n",
      "2021-09-22 09:09:36,968 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2021-09-22 09:09:36,968 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 17128.94358646904 word corpus (78.7%% of prior 21762)', 'datetime': '2021-09-22T09:09:36.968714', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-22 09:09:37,035 : INFO : estimated required memory for 4182 words and 300 dimensions: 12127800 bytes\n",
      "2021-09-22 09:09:37,035 : INFO : resetting layer weights\n",
      "2021-09-22 09:09:37,035 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-22T09:09:37.035861', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-09-22 09:09:37,035 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4182 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=20 window=5 shrink_windows=True', 'datetime': '2021-09-22T09:09:37.035861', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-22 09:09:37,088 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,170 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,173 : INFO : EPOCH - 1 : training on 21762 raw words (17067 effective words) took 0.1s, 147758 effective words/s\n",
      "2021-09-22 09:09:37,227 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,277 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,297 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,298 : INFO : EPOCH - 2 : training on 21762 raw words (17164 effective words) took 0.1s, 144047 effective words/s\n",
      "2021-09-22 09:09:37,408 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,420 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,471 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,473 : INFO : EPOCH - 3 : training on 21762 raw words (17068 effective words) took 0.2s, 100792 effective words/s\n",
      "2021-09-22 09:09:37,513 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,562 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,568 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,569 : INFO : EPOCH - 4 : training on 21762 raw words (17105 effective words) took 0.1s, 186371 effective words/s\n",
      "2021-09-22 09:09:37,622 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,683 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,694 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,696 : INFO : EPOCH - 5 : training on 21762 raw words (17156 effective words) took 0.1s, 141777 effective words/s\n",
      "2021-09-22 09:09:37,754 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,806 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,820 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,822 : INFO : EPOCH - 6 : training on 21762 raw words (17175 effective words) took 0.1s, 145084 effective words/s\n",
      "2021-09-22 09:09:37,876 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,926 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,935 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,936 : INFO : EPOCH - 7 : training on 21762 raw words (17143 effective words) took 0.1s, 156191 effective words/s\n",
      "2021-09-22 09:09:37,994 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,027 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,051 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,052 : INFO : EPOCH - 8 : training on 21762 raw words (17101 effective words) took 0.1s, 155561 effective words/s\n",
      "2021-09-22 09:09:38,096 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,138 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,154 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,155 : INFO : EPOCH - 9 : training on 21762 raw words (17080 effective words) took 0.1s, 178142 effective words/s\n",
      "2021-09-22 09:09:38,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,218 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,238 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,238 : INFO : EPOCH - 10 : training on 21762 raw words (17148 effective words) took 0.1s, 203543 effective words/s\n",
      "2021-09-22 09:09:38,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,319 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,338 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,338 : INFO : EPOCH - 11 : training on 21762 raw words (17143 effective words) took 0.1s, 172634 effective words/s\n",
      "2021-09-22 09:09:38,388 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,439 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,439 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,439 : INFO : EPOCH - 12 : training on 21762 raw words (17115 effective words) took 0.1s, 187041 effective words/s\n",
      "2021-09-22 09:09:38,488 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,521 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,539 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,539 : INFO : EPOCH - 13 : training on 21762 raw words (17151 effective words) took 0.1s, 181897 effective words/s\n",
      "2021-09-22 09:09:38,588 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,621 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,639 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,655 : INFO : EPOCH - 14 : training on 21762 raw words (17110 effective words) took 0.1s, 166142 effective words/s\n",
      "2021-09-22 09:09:38,705 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,739 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,755 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,755 : INFO : EPOCH - 15 : training on 21762 raw words (17163 effective words) took 0.1s, 164509 effective words/s\n",
      "2021-09-22 09:09:38,802 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,839 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,855 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,855 : INFO : EPOCH - 16 : training on 21762 raw words (17034 effective words) took 0.1s, 179817 effective words/s\n",
      "2021-09-22 09:09:38,901 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,974 : INFO : EPOCH - 17 : training on 21762 raw words (17142 effective words) took 0.1s, 150759 effective words/s\n",
      "2021-09-22 09:09:39,023 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,056 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,073 : INFO : EPOCH - 18 : training on 21762 raw words (17136 effective words) took 0.1s, 175644 effective words/s\n",
      "2021-09-22 09:09:39,142 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,185 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,194 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,197 : INFO : EPOCH - 19 : training on 21762 raw words (17121 effective words) took 0.1s, 147364 effective words/s\n",
      "2021-09-22 09:09:39,255 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,300 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,322 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,323 : INFO : EPOCH - 20 : training on 21762 raw words (17091 effective words) took 0.1s, 142171 effective words/s\n",
      "2021-09-22 09:09:39,381 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,419 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,435 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,436 : INFO : EPOCH - 21 : training on 21762 raw words (17156 effective words) took 0.1s, 156669 effective words/s\n",
      "2021-09-22 09:09:39,495 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,569 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,573 : INFO : EPOCH - 22 : training on 21762 raw words (17179 effective words) took 0.1s, 130985 effective words/s\n",
      "2021-09-22 09:09:39,643 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,700 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,702 : INFO : EPOCH - 23 : training on 21762 raw words (17128 effective words) took 0.1s, 135536 effective words/s\n",
      "2021-09-22 09:09:39,744 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,796 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,805 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,807 : INFO : EPOCH - 24 : training on 21762 raw words (17118 effective words) took 0.1s, 168357 effective words/s\n",
      "2021-09-22 09:09:39,849 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,893 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,901 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,904 : INFO : EPOCH - 25 : training on 21762 raw words (17180 effective words) took 0.1s, 185671 effective words/s\n",
      "2021-09-22 09:09:39,950 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,986 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,004 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,005 : INFO : EPOCH - 26 : training on 21762 raw words (17109 effective words) took 0.1s, 173838 effective words/s\n",
      "2021-09-22 09:09:40,054 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,091 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,110 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,110 : INFO : EPOCH - 27 : training on 21762 raw words (17107 effective words) took 0.1s, 162713 effective words/s\n",
      "2021-09-22 09:09:40,142 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,191 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,191 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,191 : INFO : EPOCH - 28 : training on 21762 raw words (17115 effective words) took 0.1s, 209723 effective words/s\n",
      "2021-09-22 09:09:40,242 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,284 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,300 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,316 : INFO : EPOCH - 29 : training on 21762 raw words (17067 effective words) took 0.1s, 153269 effective words/s\n",
      "2021-09-22 09:09:40,375 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,422 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,423 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,423 : INFO : EPOCH - 30 : training on 21762 raw words (17156 effective words) took 0.1s, 159207 effective words/s\n",
      "2021-09-22 09:09:40,487 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,503 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,520 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,520 : INFO : EPOCH - 31 : training on 21762 raw words (17102 effective words) took 0.1s, 174782 effective words/s\n",
      "2021-09-22 09:09:40,567 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,636 : INFO : EPOCH - 32 : training on 21762 raw words (17188 effective words) took 0.1s, 169021 effective words/s\n",
      "2021-09-22 09:09:40,675 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,741 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,742 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,742 : INFO : EPOCH - 33 : training on 21762 raw words (17161 effective words) took 0.1s, 151520 effective words/s\n",
      "2021-09-22 09:09:40,808 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,859 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,877 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,877 : INFO : EPOCH - 34 : training on 21762 raw words (17116 effective words) took 0.1s, 132970 effective words/s\n",
      "2021-09-22 09:09:40,930 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,975 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,991 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,991 : INFO : EPOCH - 35 : training on 21762 raw words (17060 effective words) took 0.1s, 157179 effective words/s\n",
      "2021-09-22 09:09:40,991 : INFO : Word2Vec lifecycle event {'msg': 'training on 761670 raw words (599355 effective words) took 4.0s, 151621 effective words/s', 'datetime': '2021-09-22T09:09:40.991924', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-22 09:09:40,991 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4182, vector_size=300, alpha=0.025)', 'datetime': '2021-09-22T09:09:40.991924', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_strugackie6 = gensim.models.Word2Vec(data, vector_size=300, window=5, epochs = 35, negative = 20, ns_exponent = 0.75, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4182\n"
     ]
    }
   ],
   "source": [
    "print(len(model_strugackie6.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model_strugackie6.wv.key_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ряшка_NOUN', 0.6155922412872314),\n",
       " ('барбридж_NOUN', 0.5065398216247559),\n",
       " ('рука_NOUN', 0.41529443860054016)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie6.wv.most_similar(positive=[\"рэдрик_NOUN\"], negative=[\"сталкер_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('барбридж_NOUN', 0.9445749521255493),\n",
       " ('хрипатый_ADJF', 0.9275789856910706),\n",
       " ('снова_ADVB', 0.8969085812568665)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie6.wv.most_similar(positive=[\"рэдрик_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75653267"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie6.wv.similarity(\"рэдрик_NOUN\", \"гута_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4559571"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie6.wv.similarity(\"рэдрик_NOUN\", \"кирилл_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8581152"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie6.wv.similarity(\"кирилл_NOUN\", \"гута_NOUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained model performs better than anyone tried before on each test. It also shows a difference in similarity coefficients for vectors рэдрик_NOUN, гута_NOUN and кирилл_NOUN. However, this difference is not expected. Probably, the initial hypothesis is flawed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'зона_NOUN'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie6.wv.doesnt_match(\"рэдрик_NOUN зона_NOUN барбридж_NOUN кирилл_NOUN мартышка_NOUN дина_NOUN\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is even more logical that in the previous model, because in this case the model identifies an inanimate object as an odd one out among the animate entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Visualize the results of the training and testing (one plot or one graph), comment on the visualization -- 1 point**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if the final model is adequate, let us build a visualisation showing clusters of characters. The hypothesis behind this experiment is that vectors for Redrik, Guta, Martyshka, Kirill, Barbridzh, Artur and Dina will cluster in a way that will be consistent with the relationships bwtween those characters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['рэдрик_NOUN', 'кирилл_NOUN', 'гута_NOUN','мартышка_NOUN', 'барбридж_NOUN', 'дина_NOUN', 'артур_NOUN']\n",
    "X = model_strugackie6.wv[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(coords[:, 0], coords[:, 1], color='red')\n",
    "plt.title('Words')\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(coords[i, 0], coords[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained visualisation is exceptionally successfull. As can be seen from the picture above, we have three clustrs each containing two terms. The central cluster brings together Matryshka and Guta, which is only reasonable, since they form a family in the novel. The right most cluster includes Redrik and Barbrigzh. This probably reflects the facts that both characters are stalkers and friends, and have visited Zona together many times. The third cluster comprises Dina and Artur who are siblings in the model. The fact that Kirill does not cluster with anyone clearly shows that his character is alienete to the world described."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Choose two sentences from the original text and substitute all the meaningful words with their closest neighbours from your word2vec model (1 point), do the agreement on the sentences with substitutions (1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had some problems understanding this task. It seemed a bit dull to me to specify inflection features of  words in a new sentence manually (at least I did not understand how it can be done automatically, since there is no place from where the code can take a set of agreement features for a semantically odd new sentence). So I decide for each new word obtained to specify a set of features available for the word it was taken instead of. For this I had to control for a new word to be of the same part of speech as the replaced word (this is why I had to preserve these features in the model). Moreover, I had to control for the features of the new and the old word not to clash. This is what expected, for example, if an obtained new noun is animate, while an old nominal term was inanimate. The feature of inanimacy can not be implemented on an animate noun in any case. The code below deliberately refuses to deal with a number of problems that arose during the work. First, it only seeks for the top five neighbors of the original term and then checks if any o them is of the same part of speech as the original token. If none of the found neighbors is of the same part of speech as the original word, the original term is kept. Otherwise, it would cost me a number of additional dull iterations of the same lines of code. Second, if the morphological analyser was not able to specify the inflection features of the original token correctly, the flawed set of features was transmitted to the new term without any correction. This is the case with the word \"пришелецы_NOUN\". As can be seen from the results, for this word the morphological analyser failed to specify the plurality feature. For this reason, the agreement in the second sentence is incorrect. Since I'm not aware of any technique to verify agreemnt automatically, I decided not to do it manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = 'Сам факт Посещения является наиболее важным открытием не только за истекшие тринадцать лет но и за все время существования человечества. Не так уж важно кто были эти пришельцы'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sentences.split('.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Сам факт Посещения является наиболее важным открытием не только за истекшие тринадцать лет но и за все время существования человечества', ' Не так уж важно кто были эти пришельцы']\n"
     ]
    }
   ],
   "source": [
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The results of the implementation of the code below are fully preserved to allow you to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сам\n",
      "['sing', 'nomn']\n",
      "сам_ADJF\n",
      "[('бредить_INFN', 0.9499155282974243), ('я_NPRO', 0.9416914582252502), ('даже_PRCL', 0.9415504932403564), ('сердито_ADVB', 0.9402171969413757), ('а_CONJ', 0.9317688345909119)]\n",
      "бредить_INFN\n",
      "INFN\n",
      "('я_NPRO', 0.9416914582252502)\n",
      "я_NPRO\n",
      "NPRO\n",
      "('даже_PRCL', 0.9415504932403564)\n",
      "('сердито_ADVB', 0.9402171969413757)\n",
      "('а_CONJ', 0.9317688345909119)\n",
      "сам HuRAAAAAA\n",
      "['sing', 'nomn']\n",
      "сам HURAAAAAAAAA\n",
      "THe enad\n",
      "факт\n",
      "['nomn']\n",
      "факт_NOUN\n",
      "[('собираться_INFN', 0.9989069104194641), ('наиболее_ADVB', 0.9987283945083618), ('мама_NOUN', 0.9985398054122925), ('закладывать_INFN', 0.9985182881355286), ('распоряжаться_INFN', 0.9985096454620361)]\n",
      "собираться_INFN\n",
      "INFN\n",
      "('наиболее_ADVB', 0.9987283945083618)\n",
      "наиболее_ADVB\n",
      "ADVB\n",
      "('мама_NOUN', 0.9985398054122925)\n",
      "мама_NOUN HuRAAAAAA\n",
      "['nomn']\n",
      "мама HURAAAAAAAAA\n",
      "THe enad\n",
      "Посещения\n",
      "['gent']\n",
      "посещение_NOUN\n",
      "[('город_NOUN', 0.9908337593078613), ('молоко_NOUN', 0.9907938838005066), ('закапывать_INFN', 0.9893375039100647), ('жучковпаучок_NOUN', 0.988673210144043), ('всего_ADJF', 0.9879376292228699)]\n",
      "город_NOUN\n",
      "NOUN\n",
      "город_NOUN HuRAAAAAA\n",
      "['gent']\n",
      "города HURAAAAAAAAA\n",
      "THe enad\n",
      "является\n",
      "['impf', '3per', 'pres', 'indc']\n",
      "являться_VERB\n",
      "являться_VERB HuRAAAAAA\n",
      "['impf', '3per', 'pres', 'indc']\n",
      "является HURAAAAAAAAA\n",
      "THe enad\n",
      "наиболее\n",
      "[]\n",
      "THe enad\n",
      "важным\n",
      "['sing', 'ablt']\n",
      "важный_ADJF\n",
      "[('уверенный_ADJF', 0.9981768727302551), ('узнавать_INFN', 0.9981726408004761), ('мереть_INFN', 0.9979825019836426), ('разговаривать_INFN', 0.997803270816803), ('очкарик_NOUN', 0.9974892735481262)]\n",
      "уверенный_ADJF\n",
      "ADJF\n",
      "уверенный_ADJF HuRAAAAAA\n",
      "['sing', 'ablt']\n",
      "уверенным HURAAAAAAAAA\n",
      "THe enad\n",
      "открытием\n",
      "['ablt']\n",
      "открытие_NOUN\n",
      "[('серьезный_ADJF', 0.9986341595649719), ('вероятно_CONJ', 0.9986300468444824), ('впервые_ADVB', 0.9970818161964417), ('непонятно_ADVB', 0.9967312216758728), ('однако_CONJ', 0.9966637492179871)]\n",
      "серьезный_ADJF\n",
      "ADJF\n",
      "('вероятно_CONJ', 0.9986300468444824)\n",
      "вероятно_CONJ\n",
      "CONJ\n",
      "('впервые_ADVB', 0.9970818161964417)\n",
      "('непонятно_ADVB', 0.9967312216758728)\n",
      "('однако_CONJ', 0.9966637492179871)\n",
      "открытие HuRAAAAAA\n",
      "['ablt']\n",
      "открытием HURAAAAAAAAA\n",
      "THe enad\n",
      "не\n",
      "[]\n",
      "THe enad\n",
      "только\n",
      "[]\n",
      "THe enad\n",
      "за\n",
      "[]\n",
      "THe enad\n",
      "истекшие\n",
      "['nomn']\n",
      "истекший_ADJF\n",
      "[('вопрос_NOUN', 0.9975489377975464), ('шерстка_NOUN', 0.9975398778915405), ('забросить_INFN', 0.997526228427887), ('мертвый_NOUN', 0.9974285960197449), ('платить_INFN', 0.9974076151847839)]\n",
      "вопрос_NOUN\n",
      "NOUN\n",
      "('шерстка_NOUN', 0.9975398778915405)\n",
      "шерстка_NOUN\n",
      "NOUN\n",
      "('забросить_INFN', 0.997526228427887)\n",
      "('мертвый_NOUN', 0.9974285960197449)\n",
      "('платить_INFN', 0.9974076151847839)\n",
      "истекший HuRAAAAAA\n",
      "['nomn']\n",
      "истекший HURAAAAAAAAA\n",
      "THe enad\n",
      "тринадцать\n",
      "[]\n",
      "тринадцать_NUMR\n",
      "[('прошлый_ADJF', 0.9978258609771729), ('комиссия_NOUN', 0.9972296357154846), ('консультант_NOUN', 0.9971507787704468), ('оклад_NOUN', 0.9971199035644531), ('существование_NOUN', 0.9968302249908447)]\n",
      "прошлый_ADJF\n",
      "ADJF\n",
      "('комиссия_NOUN', 0.9972296357154846)\n",
      "комиссия_NOUN\n",
      "NOUN\n",
      "('консультант_NOUN', 0.9971507787704468)\n",
      "('оклад_NOUN', 0.9971199035644531)\n",
      "('существование_NOUN', 0.9968302249908447)\n",
      "тринадцать HuRAAAAAA\n",
      "[]\n",
      "тринадцать HURAAAAAAAAA\n",
      "THe enad\n",
      "лет\n",
      "['gent']\n",
      "год_NOUN\n",
      "[('час_NOUN', 0.9916371703147888), ('сто_NOUN', 0.9868099689483643), ('двадцать_NUMR', 0.9860250949859619), ('между_PREP', 0.984811007976532), ('упасти_INFN', 0.9844927191734314)]\n",
      "час_NOUN\n",
      "NOUN\n",
      "час_NOUN HuRAAAAAA\n",
      "['gent']\n",
      "часа HURAAAAAAAAA\n",
      "THe enad\n",
      "но\n",
      "[]\n",
      "THe enad\n",
      "и\n",
      "[]\n",
      "THe enad\n",
      "за\n",
      "[]\n",
      "THe enad\n",
      "все\n",
      "[]\n",
      "THe enad\n",
      "время\n",
      "['accs']\n",
      "время_NOUN\n",
      "[('некоторый_ADJF', 0.9309893846511841), ('от_PREP', 0.9240998029708862), ('стоять_INFN', 0.9064339399337769), ('сторона_NOUN', 0.9010434150695801), ('привычка_NOUN', 0.8959077000617981)]\n",
      "некоторый_ADJF\n",
      "ADJF\n",
      "('от_PREP', 0.9240998029708862)\n",
      "от_PREP\n",
      "PREP\n",
      "('стоять_INFN', 0.9064339399337769)\n",
      "('сторона_NOUN', 0.9010434150695801)\n",
      "сторона_NOUN HuRAAAAAA\n",
      "['accs']\n",
      "сторону HURAAAAAAAAA\n",
      "THe enad\n",
      "существования\n",
      "['gent']\n",
      "существование_NOUN\n",
      "[('сторонка_NOUN', 0.9981769323348999), ('сбоку_ADVB', 0.9979127645492554), ('кладбище_NOUN', 0.9977166652679443), ('деликатно_ADVB', 0.9976757168769836), ('зевать_INFN', 0.9976224899291992)]\n",
      "сторонка_NOUN\n",
      "NOUN\n",
      "сторонка_NOUN HuRAAAAAA\n",
      "['gent']\n",
      "сторонки HURAAAAAAAAA\n",
      "THe enad\n",
      "человечества\n",
      "['gent']\n",
      "человечество_NOUN\n",
      "[('оно_NPRO', 0.9991969466209412), ('более_ADVB', 0.9991881251335144), ('шитокрыть_INFN', 0.9990331530570984), ('пахнуть_INFN', 0.9989485144615173), ('заплакать_INFN', 0.9988934993743896)]\n",
      "оно_NPRO\n",
      "NPRO\n",
      "('более_ADVB', 0.9991881251335144)\n",
      "более_ADVB\n",
      "ADVB\n",
      "('шитокрыть_INFN', 0.9990331530570984)\n",
      "('пахнуть_INFN', 0.9989485144615173)\n",
      "('заплакать_INFN', 0.9988934993743896)\n",
      "человечество HuRAAAAAA\n",
      "['gent']\n",
      "человечества HURAAAAAAAAA\n",
      "THe enad\n",
      "сам мама города является наиболее уверенным открытием не только за истекший тринадцать часа но и за все сторону сторонки человечества\n",
      "Не\n",
      "[]\n",
      "THe enad\n",
      "так\n",
      "[]\n",
      "THe enad\n",
      "уж\n",
      "[]\n",
      "THe enad\n",
      "важно\n",
      "['Prdx']\n",
      "THe enad\n",
      "кто\n",
      "['nomn']\n",
      "кто_NPRO\n",
      "[('это_PRCL', 0.974466860294342), ('если_CONJ', 0.9692867398262024), ('что_CONJ', 0.968459963798523), ('здесь_ADVB', 0.9678905606269836), ('быть_INFN', 0.9646321535110474)]\n",
      "это_PRCL\n",
      "PRCL\n",
      "('если_CONJ', 0.9692867398262024)\n",
      "если_CONJ\n",
      "CONJ\n",
      "('что_CONJ', 0.968459963798523)\n",
      "('здесь_ADVB', 0.9678905606269836)\n",
      "('быть_INFN', 0.9646321535110474)\n",
      "кто HuRAAAAAA\n",
      "['nomn']\n",
      "кто HURAAAAAAAAA\n",
      "THe enad\n",
      "были\n",
      "['impf', 'past', 'indc']\n",
      "быть_VERB\n",
      "быть_VERB HuRAAAAAA\n",
      "['impf', 'past', 'indc']\n",
      "были HURAAAAAAAAA\n",
      "THe enad\n",
      "эти\n",
      "['Subx', 'Apro', 'nomn']\n",
      "этот_ADJF\n",
      "[('каждый_ADJF', 0.9606833457946777), ('последний_ADJF', 0.953863799571991), ('посещение_NOUN', 0.9505617618560791), ('квартал_NOUN', 0.9475405812263489), ('чумная_ADJF', 0.9469196796417236)]\n",
      "каждый_ADJF\n",
      "ADJF\n",
      "каждый_ADJF HuRAAAAAA\n",
      "['Subx', 'Apro', 'nomn']\n",
      "каждый HURAAAAAAAAA\n",
      "THe enad\n",
      "пришельцы\n",
      "['nomn']\n",
      "пришелец_NOUN\n",
      "[('какаято_PRTS', 0.9992594122886658), ('кость_NOUN', 0.9989877343177795), ('страшно_ADVB', 0.998884916305542), ('попробовать_INFN', 0.9988200664520264), ('суть_VERB', 0.9987511038780212)]\n",
      "какаято_PRTS\n",
      "PRTS\n",
      "('кость_NOUN', 0.9989877343177795)\n",
      "кость_NOUN\n",
      "NOUN\n",
      "кость_NOUN HuRAAAAAA\n",
      "['nomn']\n",
      "кость HURAAAAAAAAA\n",
      "THe enad\n",
      "Не так уж важно кто были каждый кость\n"
     ]
    }
   ],
   "source": [
    "new_sents = []\n",
    "stops = ['PREP', 'CONJ', 'PRCL', 'INTJ', 'ADVB']\n",
    "for l in lines:\n",
    "    new_bag = []\n",
    "    words = l.split()\n",
    "    for w in words:\n",
    "        print(w)\n",
    "        ana = morph.parse(w)[0].tag\n",
    "        feats = str(ana).split(',')\n",
    "        if len(feats[0]) > 4:\n",
    "            feats[0] = feats[0].split(' ')[0]\n",
    "        feats2 = feats[1:]\n",
    "        feats3 = []\n",
    "        for f in feats2:\n",
    "            if len(f) > 4:\n",
    "                continue\n",
    "            if f == \"anim\" or f == \"inan\":\n",
    "                continue\n",
    "            else:\n",
    "                feats3.append(f)\n",
    "        print(feats3)\n",
    "        if feats[0] in stops:\n",
    "            x  = w\n",
    "        else:\n",
    "            lemma = m.lemmatize(w)[0]\n",
    "            lemma_1 = lemma + '_' + str(feats[0])\n",
    "            print(lemma_1)\n",
    "            if lemma_1 in list(model_strugackie6.wv.key_to_index.keys()):\n",
    "                    substitutes = model_strugackie6.wv.most_similar(positive=[lemma_1], topn=5)\n",
    "                    print(substitutes)\n",
    "                    substitute = substitutes[0]\n",
    "                    new_lemma = substitute[0] \n",
    "                    print(new_lemma)\n",
    "                    POS_new_lemma = new_lemma.split('_')[1]\n",
    "                    print(POS_new_lemma)\n",
    "                    if POS_new_lemma == str(feats[0]):\n",
    "                        act_substitute = new_lemma\n",
    "                    else:\n",
    "                        substitute1 =  substitutes[1]\n",
    "                        print(substitute1)\n",
    "                        new_lemma1 = substitute1[0]\n",
    "                        print(new_lemma1)\n",
    "                        POS_new_lemma1 = new_lemma1.split('_')[1]\n",
    "                        print(POS_new_lemma1)\n",
    "                        if POS_new_lemma1 == str(feats[0]):\n",
    "                            act_substitute = new_lemma1\n",
    "                        else:\n",
    "                            substitute2 = substitutes[2]\n",
    "                            print(substitute2)\n",
    "                            new_lemma2 = substitute2[0]\n",
    "                            POS_new_lemma2 = new_lemma2.split('_')[1]\n",
    "                            if POS_new_lemma2 == str(feats[0]):\n",
    "                                act_substitute = new_lemma2 \n",
    "                            else:\n",
    "                                substitute3 = substitutes[3]\n",
    "                                print(substitute3)\n",
    "                                new_lemma3 = substitute3[0]\n",
    "                                POS_new_lemma3 = new_lemma3.split('_')[1]\n",
    "                                if POS_new_lemma3 == str(feats[0]):\n",
    "                                    act_substitute = new_lemma3\n",
    "                                else:\n",
    "                                    substitute4 = substitutes[4]\n",
    "                                    print(substitute4)\n",
    "                                    new_lemma4 = substitute4[0]\n",
    "                                    POS_new_lemma4 = new_lemma4.split('_')[1]\n",
    "                                    if POS_new_lemma3 == str(feats[0]):\n",
    "                                        act_substitute = new_lemma4 \n",
    "                                    else:\n",
    "                                        act_substitute = lemma\n",
    "            else:\n",
    "                act_substitute = lemma_1\n",
    "            print(act_substitute, \"HuRAAAAAA\")\n",
    "            i = 0\n",
    "            x =  act_substitute.split('_')[0]\n",
    "            print(feats3)\n",
    "            while i < len(feats3):\n",
    "                an = morph.parse(x)[0]\n",
    "                fea = str(feats3[i])\n",
    "                new_form = an.inflect({fea}).word\n",
    "                x = new_form\n",
    "                i = i + 1\n",
    "            print(x, \"HURAAAAAAAAA\")\n",
    "        print(\"THe enad\")\n",
    "        new_bag.append(x)\n",
    "    new_sent = ' '.join(new_bag)\n",
    "    print(new_sent)\n",
    "    new_sents.append(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['сам мама города является наиболее уверенным открытием не только за истекший тринадцать часа но и за все сторону сторонки человечества', 'Не так уж важно кто были каждый кость']\n"
     ]
    }
   ],
   "source": [
    "print(new_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
