{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Choose a long text (a novel), do preprocessing on it (delete punctuation, lemmatize it, make sure that every sentence starts on a new line), don't forget to put the lemmatized text or a link to your lemmatized text into your hw folder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen \"Roadside picnic\"  by Arkadiy and Boris Strugackie. I have cut off the second part of the text, since lemmatization of the whole novel was problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import operator\n",
    "from string import punctuation\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import gensim\n",
    "import logging\n",
    "import nltk.data\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    words = ''\n",
    "    p = list(punctuation)\n",
    "    for i in range(len(s)):\n",
    "        if s[i] in p:\n",
    "            continue\n",
    "        words = words + s[i]\n",
    "    phrase = str(words)\n",
    "    spltd = phrase.split()\n",
    "    return spltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('strugackie_preproc_1.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text.splitlines() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below I augment a string containing a part of speech of the word analysed to the string representing lemma. This decision is driven by the need to —Åarry out agreement in task 5. A more detailed explanation of the techniques is given before the code for task 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines2= []\n",
    "for l in lines:\n",
    "    line = ' '.join(tokenize(l))\n",
    "    lemmas = m.lemmatize(line)\n",
    "    lemmas2 = []\n",
    "    for l in lemmas:\n",
    "        l_ana = morph.parse(l)[0]\n",
    "        POS = str(l_ana.tag.POS)\n",
    "        l_new = l+ '_' + POS\n",
    "        if l_new == ' _None':\n",
    "            pass\n",
    "        else:\n",
    "            lemmas2.append(l_new)\n",
    "    line2 = ' '.join(lemmas2)\n",
    "    lines2.append(line2)\n",
    "tex2 = '\\n'.join(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(\"strugackie2.txt\", \"w+\")\n",
    "my_file.write(tex2)\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Train a word2vec model on the chosen text, set the parameters (window size, vector size, number of iterations etc.), comment on your choice of parameter settings and the reasoning behind it, experiment with the settings and show me that you have chosen the settings after some experimentation and consideration -- 2 points**\n",
    "\n",
    "**3.Test your model, use most_similar, similarity, doesnt_match functions, comment on the model performance, explain the reasoning behind the testing -- 2 points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'strugackie2.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us implement the following paramaters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 17:57:31,484 : INFO : collecting all words and their counts\n",
      "2021-09-21 17:57:31,495 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-21 17:57:31,530 : INFO : collected 4182 word types from a corpus of 21762 raw words and 2531 sentences\n",
      "2021-09-21 17:57:31,532 : INFO : Creating a fresh vocabulary\n",
      "2021-09-21 17:57:31,556 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1891 unique words (45.21759923481588%% of original 4182, drops 2291)', 'datetime': '2021-09-21T17:57:31.556443', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:57:31,559 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 19471 word corpus (89.47247495634592%% of original 21762, drops 2291)', 'datetime': '2021-09-21T17:57:31.559754', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:57:31,591 : INFO : deleting the raw counts dictionary of 4182 items\n",
      "2021-09-21 17:57:31,593 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2021-09-21 17:57:31,595 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 14540.499420536875 word corpus (74.7%% of prior 19471)', 'datetime': '2021-09-21T17:57:31.595573', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:57:31,662 : INFO : estimated required memory for 1891 words and 300 dimensions: 5483900 bytes\n",
      "2021-09-21 17:57:31,664 : INFO : resetting layer weights\n",
      "2021-09-21 17:57:31,675 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-21T17:57:31.675317', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-09-21 17:57:31,677 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1891 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=15 shrink_windows=True', 'datetime': '2021-09-21T17:57:31.677317', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:57:31,739 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:57:31,755 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:57:31,768 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:57:31,770 : INFO : EPOCH - 1 : training on 21762 raw words (14501 effective words) took 0.1s, 176730 effective words/s\n",
      "2021-09-21 17:57:31,840 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:57:31,846 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:57:31,867 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:57:31,870 : INFO : EPOCH - 2 : training on 21762 raw words (14481 effective words) took 0.1s, 161514 effective words/s\n",
      "2021-09-21 17:57:31,925 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:57:31,949 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:57:31,955 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:57:31,957 : INFO : EPOCH - 3 : training on 21762 raw words (14593 effective words) took 0.1s, 187631 effective words/s\n",
      "2021-09-21 17:57:32,028 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:57:32,032 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:57:32,054 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:57:32,056 : INFO : EPOCH - 4 : training on 21762 raw words (14558 effective words) took 0.1s, 162341 effective words/s\n",
      "2021-09-21 17:57:32,127 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:57:32,132 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:57:32,157 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:57:32,158 : INFO : EPOCH - 5 : training on 21762 raw words (14557 effective words) took 0.1s, 158421 effective words/s\n",
      "2021-09-21 17:57:32,160 : INFO : Word2Vec lifecycle event {'msg': 'training on 108810 raw words (72690 effective words) took 0.5s, 150928 effective words/s', 'datetime': '2021-09-21T17:57:32.160496', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:57:32,161 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1891, vector_size=300, alpha=0.025)', 'datetime': '2021-09-21T17:57:32.161495', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_strugackie1 = gensim.models.Word2Vec(data, vector_size=300, window=15, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    }
   ],
   "source": [
    "print(len(model_strugackie1.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test my model, I formulated several hypotheses:\n",
    "1. If a model is good enough, it should provide reasonable results for a query aiming at identifying words which describe Redrik (—Ä—ç–¥—Ä–∏–∫_NOUN) as a person, but not as a stalker (—Å—Ç–∞–ª–∫–µ—Ä_NOUN).\n",
    "2. If a model is good enough, it should provide reasonable results for a query seeking words that can be representative of Redrik as a character in general.\n",
    "3. If a model is good enough, it should predict vectors for —Ä—ç—Ä–∏–∫_NOUN and –≥—É—Ç–∞_NOUN, as well as —Ä—ç–¥—Ä–∏–∫_NOUN and –∫–∏—Ä–∏–ª–ª_NOUN to show a higher similarity coefficient than vectors for –≥—É—Ç–∞_NOUN and –∫–∏—Ä–∏–ª–ª_NOUN, sincee characters of Guta and Kirill do not occur in the same scene in the novel.\n",
    "4. If a model is good enough, it should be able to identify –º–∞—Ä—Ç—ã—à–∫–∞_NOUN as an odd one out in the list of —Ä—ç–¥—Ä–∏–∫_NOUN –∑–æ–Ω–∞_NOUN –±–∞—Ä–±—Ä–∏–¥–∂_NOUN –∫–∏—Ä–∏–ª–ª_NOUN, as the character of Martyshka does not visit Zona in the original story.\n",
    "I will use functions `most_similar`, `similarity`, `doesnt_match` specified in the task, to check if the outlined above hyposes hold for each model.\n",
    "\n",
    "\n",
    "Further on, I will only comment on the cases where a models seems not to provide a satisfactory result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–ø—Ä–æ—Ç–µ–∑_NOUN', 0.08394461870193481),\n",
       " ('–≤—ã—Ä–µ–∑_NOUN', 0.06946960836648941),\n",
       " ('–≤–µ—Ä–Ω—ã–π_ADJF', 0.06739284098148346)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie1.wv.most_similar(positive=[\"—Ä—ç–¥—Ä–∏–∫_NOUN\"], negative=[\"—Å—Ç–∞–ª–∫–µ—Ä_NOUN\"], topn=3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–∏_CONJ', 0.9999586939811707),\n",
       " ('–Ω–∞_PREP', 0.9999536871910095),\n",
       " ('—Å_PREP', 0.9999494552612305)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie1.wv.most_similar(positive=[\"—Ä—ç–¥—Ä–∏–∫_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the result above, the present model fails to provide satisfactory list of terms describing Redrik as a character. The resulting terms are simply the most frequent ones in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998583"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie1.wv.similarity(\"—Ä—ç–¥—Ä–∏–∫_NOUN\", \"–≥—É—Ç–∞_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99983233"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie1.wv.similarity(\"—Ä—ç–¥—Ä–∏–∫_NOUN\", \"–∫–∏—Ä–∏–ª–ª_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997754"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie1.wv.similarity(\"–∫–∏—Ä–∏–ª–ª_NOUN\", \"–≥—É—Ç–∞_NOUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity coefficients are pretty similar for all the three pairs compaired. This can be either because the model is weak, or the original hypothesis is plain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–º–∞—Ä—Ç—ã—à–∫–∞_NOUN'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie1.wv.doesnt_match(\"—Ä—ç–¥—Ä–∏–∫_NOUN –∑–æ–Ω–∞_NOUN –±–∞—Ä–±—Ä–∏–¥–∂_NOUN –∫–∏—Ä–∏–ª–ª_NOUN –º–∞—Ä—Ç—ã—à–∫–∞_NOUN\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us increase the number of trainings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 17:58:05,627 : INFO : collecting all words and their counts\n",
      "2021-09-21 17:58:05,630 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-21 17:58:05,677 : INFO : collected 4182 word types from a corpus of 21762 raw words and 2531 sentences\n",
      "2021-09-21 17:58:05,679 : INFO : Creating a fresh vocabulary\n",
      "2021-09-21 17:58:05,711 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1891 unique words (45.21759923481588%% of original 4182, drops 2291)', 'datetime': '2021-09-21T17:58:05.711203', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:58:05,713 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 19471 word corpus (89.47247495634592%% of original 21762, drops 2291)', 'datetime': '2021-09-21T17:58:05.712203', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:58:05,755 : INFO : deleting the raw counts dictionary of 4182 items\n",
      "2021-09-21 17:58:05,756 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2021-09-21 17:58:05,758 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 14540.499420536875 word corpus (74.7%% of prior 19471)', 'datetime': '2021-09-21T17:58:05.758832', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:58:05,843 : INFO : estimated required memory for 1891 words and 300 dimensions: 5483900 bytes\n",
      "2021-09-21 17:58:05,845 : INFO : resetting layer weights\n",
      "2021-09-21 17:58:05,855 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-21T17:58:05.855633', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-09-21 17:58:05,857 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1891 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=15 shrink_windows=True', 'datetime': '2021-09-21T17:58:05.857550', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:58:05,918 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:58:05,924 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:58:05,938 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:58:05,940 : INFO : EPOCH - 1 : training on 21762 raw words (14501 effective words) took 0.1s, 209338 effective words/s\n",
      "2021-09-21 17:58:05,993 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:58:05,999 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:58:06,020 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:58:06,023 : INFO : EPOCH - 2 : training on 21762 raw words (14481 effective words) took 0.1s, 191741 effective words/s\n",
      "2021-09-21 17:58:06,084 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:58:06,087 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:58:06,109 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:58:06,112 : INFO : EPOCH - 3 : training on 21762 raw words (14593 effective words) took 0.1s, 180267 effective words/s\n",
      "2021-09-21 17:58:06,114 : INFO : Word2Vec lifecycle event {'msg': 'training on 65286 raw words (43575 effective words) took 0.3s, 170810 effective words/s', 'datetime': '2021-09-21T17:58:06.114489', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:58:06,116 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1891, vector_size=300, alpha=0.025)', 'datetime': '2021-09-21T17:58:06.116049', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_strugackie2 = gensim.models.Word2Vec(data, vector_size=300, window=15, min_count=2, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    }
   ],
   "source": [
    "print(len(model_strugackie2.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–≤–æ—Å—Ç—Ä–æ–Ω–æ—Å—ã–π_ADJF', 0.12317244708538055),\n",
       " ('–≤—ã–¥–µ—Ä–∂–∏–≤–∞—Ç—å_INFN', 0.1169157326221466),\n",
       " ('–¥–æ—Å–∞–¥–∞_NOUN', 0.11178231984376907)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie2.wv.most_similar(positive=[\"—Ä—ç–¥—Ä–∏–∫_NOUN\"], negative=[\"—Å—Ç–∞–ª–∫–µ—Ä_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–∏_CONJ', 0.999818742275238),\n",
       " ('–Ω–∞_PREP', 0.9998012185096741),\n",
       " ('–≤_PREP', 0.9997910857200623)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie2.wv.most_similar(positive=[\"—Ä—ç–¥—Ä–∏–∫_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the result, increasing the number of trainings 3 times on it's own does not solve the problem of the most frequent tokens. It worth mentioning that introducing a \"stopwords\" module would help, however since I have all tokens in my model with an augmented \"part of speech\" string, this will not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99926007"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie2.wv.similarity(\"—Ä—ç–¥—Ä–∏–∫_NOUN\", \"–≥—É—Ç–∞_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994021"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie2.wv.similarity(\"—Ä—ç–¥—Ä–∏–∫_NOUN\", \"–∫–∏—Ä–∏–ª–ª_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99905694"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie2.wv.similarity(\"–∫–∏—Ä–∏–ª–ª_NOUN\", \"–≥—É—Ç–∞_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–º–∞—Ä—Ç—ã—à–∫–∞_NOUN'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie2.wv.doesnt_match(\"—Ä—ç–¥—Ä–∏–∫_NOUN –∑–æ–Ω–∞_NOUN –±–∞—Ä–±—Ä–∏–¥–∂_NOUN –∫–∏—Ä–∏–ª–ª_NOUN –º–∞—Ä—Ç—ã—à–∫–∞_NOUN\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the second model was not better than the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the third model, I will preserve all the paramaters as they were specified above, but the query window will be reduced to 5 to tackle the \"most frequent words\" problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-24 10:59:31,877 : INFO : collecting all words and their counts\n",
      "2021-09-24 10:59:31,922 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-24 10:59:31,962 : INFO : collected 4182 word types from a corpus of 21762 raw words and 2531 sentences\n",
      "2021-09-24 10:59:31,962 : INFO : Creating a fresh vocabulary\n",
      "2021-09-24 10:59:31,993 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1891 unique words (45.21759923481588%% of original 4182, drops 2291)', 'datetime': '2021-09-24T10:59:31.984013', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-24 10:59:31,994 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 19471 word corpus (89.47247495634592%% of original 21762, drops 2291)', 'datetime': '2021-09-24T10:59:31.994354', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-24 10:59:32,022 : INFO : deleting the raw counts dictionary of 4182 items\n",
      "2021-09-24 10:59:32,022 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2021-09-24 10:59:32,038 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 14540.499420536875 word corpus (74.7%% of prior 19471)', 'datetime': '2021-09-24T10:59:32.038677', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-24 10:59:32,082 : INFO : estimated required memory for 1891 words and 300 dimensions: 5483900 bytes\n",
      "2021-09-24 10:59:32,082 : INFO : resetting layer weights\n",
      "2021-09-24 10:59:32,089 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-24T10:59:32.089981', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-09-24 10:59:32,106 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1891 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-09-24T10:59:32.106852', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-24 10:59:33,186 : INFO : EPOCH 1 - PROGRESS: at 7.70% examples, 1165 words/s, in_qsize 2, out_qsize 1\n",
      "2021-09-24 10:59:33,186 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-24 10:59:33,186 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-24 10:59:33,203 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-24 10:59:33,203 : INFO : EPOCH - 1 : training on 21762 raw words (14554 effective words) took 1.0s, 14042 effective words/s\n",
      "2021-09-24 10:59:33,232 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-24 10:59:33,249 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-24 10:59:33,249 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-24 10:59:33,249 : INFO : EPOCH - 2 : training on 21762 raw words (14525 effective words) took 0.0s, 318830 effective words/s\n",
      "2021-09-24 10:59:33,281 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-24 10:59:33,281 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-24 10:59:33,298 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-24 10:59:33,298 : INFO : EPOCH - 3 : training on 21762 raw words (14498 effective words) took 0.0s, 350834 effective words/s\n",
      "2021-09-24 10:59:33,298 : INFO : Word2Vec lifecycle event {'msg': 'training on 65286 raw words (43577 effective words) took 1.2s, 36502 effective words/s', 'datetime': '2021-09-24T10:59:33.298030', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-24 10:59:33,298 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1891, vector_size=300, alpha=0.025)', 'datetime': '2021-09-24T10:59:33.298030', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_strugackie3 = gensim.models.Word2Vec(data, vector_size=300, window=5, min_count=2, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    }
   ],
   "source": [
    "print(len(model_strugackie3.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–¥–æ—Å–∞–¥–∞_NOUN', 0.19106616079807281),\n",
       " ('–≤–æ—Å—Ç—Ä–æ–Ω–æ—Å—ã–π_ADJF', 0.1660316288471222),\n",
       " ('–±—É–≥–æ—Ä_NOUN', 0.16057683527469635)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie3.wv.most_similar(positive=[\"—Ä—ç–¥—Ä–∏–∫_NOUN\"], negative=[\"—Å—Ç–∞–ª–∫–µ—Ä_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–∏_CONJ', 0.9983274340629578),\n",
       " ('–Ω–∞_PREP', 0.9982181191444397),\n",
       " ('–æ–Ω_NPRO', 0.997957170009613)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie3.wv.most_similar(positive=[\"—Ä—ç–¥—Ä–∏–∫_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the result obtained, reducing the window size only did not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99207306"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie3.wv.similarity(\"—Ä—ç–¥—Ä–∏–∫_NOUN\", \"–≥—É—Ç–∞_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950063"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie3.wv.similarity(\"—Ä—ç–¥—Ä–∏–∫_NOUN\", \"–∫–∏—Ä–∏–ª–ª_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907466"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie3.wv.similarity(\"–∫–∏—Ä–∏–ª–ª_NOUN\", \"–≥—É—Ç–∞_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–º–∞—Ä—Ç—ã—à–∫–∞_NOUN'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie3.wv.doesnt_match(\"—Ä—ç–¥—Ä–∏–∫_NOUN –∑–æ–Ω–∞_NOUN –±–∞—Ä–±—Ä–∏–¥–∂_NOUN –∫–∏—Ä–∏–ª–ª_NOUN –º–∞—Ä—Ç—ã—à–∫–∞_NOUN\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now consider a model that uses the skip-gram algorithm (all the other paramentes are keeped as they were specified above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 17:59:25,831 : INFO : collecting all words and their counts\n",
      "2021-09-21 17:59:25,834 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-21 17:59:25,873 : INFO : collected 4182 word types from a corpus of 21762 raw words and 2531 sentences\n",
      "2021-09-21 17:59:25,877 : INFO : Creating a fresh vocabulary\n",
      "2021-09-21 17:59:25,897 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1891 unique words (45.21759923481588%% of original 4182, drops 2291)', 'datetime': '2021-09-21T17:59:25.897292', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:59:25,898 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 19471 word corpus (89.47247495634592%% of original 21762, drops 2291)', 'datetime': '2021-09-21T17:59:25.898292', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:59:25,931 : INFO : deleting the raw counts dictionary of 4182 items\n",
      "2021-09-21 17:59:25,933 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2021-09-21 17:59:25,935 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 14540.499420536875 word corpus (74.7%% of prior 19471)', 'datetime': '2021-09-21T17:59:25.934072', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:59:26,006 : INFO : estimated required memory for 1891 words and 300 dimensions: 5483900 bytes\n",
      "2021-09-21 17:59:26,010 : INFO : resetting layer weights\n",
      "2021-09-21 17:59:26,018 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-21T17:59:26.018215', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-09-21 17:59:26,021 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1891 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-09-21T17:59:26.021649', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:59:26,105 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:26,155 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:26,173 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:26,175 : INFO : EPOCH - 1 : training on 21762 raw words (14554 effective words) took 0.1s, 100994 effective words/s\n",
      "2021-09-21 17:59:26,243 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:26,334 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:26,338 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:26,339 : INFO : EPOCH - 2 : training on 21762 raw words (14514 effective words) took 0.2s, 93081 effective words/s\n",
      "2021-09-21 17:59:26,423 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:26,482 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:26,490 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:26,492 : INFO : EPOCH - 3 : training on 21762 raw words (14511 effective words) took 0.1s, 101915 effective words/s\n",
      "2021-09-21 17:59:26,494 : INFO : Word2Vec lifecycle event {'msg': 'training on 65286 raw words (43579 effective words) took 0.5s, 92628 effective words/s', 'datetime': '2021-09-21T17:59:26.494769', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:59:26,495 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1891, vector_size=300, alpha=0.025)', 'datetime': '2021-09-21T17:59:26.495769', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_strugackie4 = gensim.models.Word2Vec(data, vector_size=300, window=5, min_count=2, sg= 1, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    }
   ],
   "source": [
    "print(len(model_strugackie4.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–æ—Ç–µ–ª—å_NOUN', 0.09701748192310333),\n",
       " ('–≤–Ω–µ_PREP', 0.05859766900539398),\n",
       " ('–≤–µ—Ä–Ω—ã–π_ADJF', 0.058121826499700546)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie4.wv.most_similar(positive=[\"—Ä—ç–¥—Ä–∏–∫_NOUN\"], negative=[\"—Å—Ç–∞–ª–∫–µ—Ä_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–¥–≤–∞_NUMR', 0.9995715022087097),\n",
       " ('—Å_PREP', 0.9995636940002441),\n",
       " ('–±–∞—Ä–±—Ä–∏–¥–∂_NOUN', 0.9995586276054382)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie4.wv.most_similar(positive=[\"—Ä—ç–¥—Ä–∏–∫_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, skip-gram model shows a better performind in the similarity test that the \"bag of words\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99937505"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie4.wv.similarity(\"—Ä—ç–¥—Ä–∏–∫_NOUN\", \"–≥—É—Ç–∞_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99934775"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie4.wv.similarity(\"—Ä—ç–¥—Ä–∏–∫_NOUN\", \"–∫–∏—Ä–∏–ª–ª_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993142"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie4.wv.similarity(\"–∫–∏—Ä–∏–ª–ª_NOUN\", \"–≥—É—Ç–∞_NOUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, none of the models studied so far gave a predicted result in the test above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–º–∞—Ä—Ç—ã—à–∫–∞_NOUN'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie4.wv.doesnt_match(\"—Ä—ç–¥—Ä–∏–∫_NOUN –∑–æ–Ω–∞_NOUN –±–∞—Ä–±—Ä–∏–¥–∂_NOUN –∫–∏—Ä–∏–ª–ª_NOUN –º–∞—Ä—Ç—ã—à–∫–∞_NOUN\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us go back to the \"bag of words\" model and increase the number of epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 17:59:48,994 : INFO : collecting all words and their counts\n",
      "2021-09-21 17:59:48,997 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-21 17:59:49,037 : INFO : collected 4182 word types from a corpus of 21762 raw words and 2531 sentences\n",
      "2021-09-21 17:59:49,039 : INFO : Creating a fresh vocabulary\n",
      "2021-09-21 17:59:49,061 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1891 unique words (45.21759923481588%% of original 4182, drops 2291)', 'datetime': '2021-09-21T17:59:49.061902', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:59:49,062 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 19471 word corpus (89.47247495634592%% of original 21762, drops 2291)', 'datetime': '2021-09-21T17:59:49.062897', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:59:49,094 : INFO : deleting the raw counts dictionary of 4182 items\n",
      "2021-09-21 17:59:49,095 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2021-09-21 17:59:49,098 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 14540.499420536875 word corpus (74.7%% of prior 19471)', 'datetime': '2021-09-21T17:59:49.098642', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-21 17:59:49,176 : INFO : estimated required memory for 1891 words and 300 dimensions: 5483900 bytes\n",
      "2021-09-21 17:59:49,179 : INFO : resetting layer weights\n",
      "2021-09-21 17:59:49,186 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-21T17:59:49.186006', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-09-21 17:59:49,188 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1891 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-09-21T17:59:49.188023', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:59:49,261 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,264 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,283 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,285 : INFO : EPOCH - 1 : training on 21762 raw words (14554 effective words) took 0.1s, 166911 effective words/s\n",
      "2021-09-21 17:59:49,348 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,352 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,370 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,371 : INFO : EPOCH - 2 : training on 21762 raw words (14514 effective words) took 0.1s, 190433 effective words/s\n",
      "2021-09-21 17:59:49,435 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,454 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,456 : INFO : EPOCH - 3 : training on 21762 raw words (14511 effective words) took 0.1s, 193743 effective words/s\n",
      "2021-09-21 17:59:49,513 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,515 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,533 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,534 : INFO : EPOCH - 4 : training on 21762 raw words (14575 effective words) took 0.1s, 212913 effective words/s\n",
      "2021-09-21 17:59:49,598 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,600 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,618 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,620 : INFO : EPOCH - 5 : training on 21762 raw words (14555 effective words) took 0.1s, 189401 effective words/s\n",
      "2021-09-21 17:59:49,688 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,713 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,714 : INFO : EPOCH - 6 : training on 21762 raw words (14584 effective words) took 0.1s, 169757 effective words/s\n",
      "2021-09-21 17:59:49,772 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,778 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,800 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,804 : INFO : EPOCH - 7 : training on 21762 raw words (14535 effective words) took 0.1s, 183761 effective words/s\n",
      "2021-09-21 17:59:49,871 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,874 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,893 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,896 : INFO : EPOCH - 8 : training on 21762 raw words (14555 effective words) took 0.1s, 179532 effective words/s\n",
      "2021-09-21 17:59:49,967 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:49,969 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:49,990 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:49,992 : INFO : EPOCH - 9 : training on 21762 raw words (14540 effective words) took 0.1s, 168416 effective words/s\n",
      "2021-09-21 17:59:50,065 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:50,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:50,091 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:50,095 : INFO : EPOCH - 10 : training on 21762 raw words (14482 effective words) took 0.1s, 159746 effective words/s\n",
      "2021-09-21 17:59:50,163 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:50,169 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:50,192 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:50,196 : INFO : EPOCH - 11 : training on 21762 raw words (14491 effective words) took 0.1s, 158035 effective words/s\n",
      "2021-09-21 17:59:50,263 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:50,267 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:50,290 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:50,294 : INFO : EPOCH - 12 : training on 21762 raw words (14535 effective words) took 0.1s, 161543 effective words/s\n",
      "2021-09-21 17:59:50,356 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:50,363 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:50,387 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:50,388 : INFO : EPOCH - 13 : training on 21762 raw words (14544 effective words) took 0.1s, 170418 effective words/s\n",
      "2021-09-21 17:59:50,451 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:50,464 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:50,480 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:50,481 : INFO : EPOCH - 14 : training on 21762 raw words (14517 effective words) took 0.1s, 173360 effective words/s\n",
      "2021-09-21 17:59:50,546 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-21 17:59:50,550 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-21 17:59:50,571 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-21 17:59:50,572 : INFO : EPOCH - 15 : training on 21762 raw words (14498 effective words) took 0.1s, 169712 effective words/s\n",
      "2021-09-21 17:59:50,574 : INFO : Word2Vec lifecycle event {'msg': 'training on 326430 raw words (217990 effective words) took 1.4s, 157450 effective words/s', 'datetime': '2021-09-21T17:59:50.574170', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-21 17:59:50,575 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1891, vector_size=300, alpha=0.025)', 'datetime': '2021-09-21T17:59:50.575377', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_strugackie5 = gensim.models.Word2Vec(data, vector_size=300, window=5, min_count=2, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    }
   ],
   "source": [
    "print(len(model_strugackie5.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–ø—Ä–æ—Ç–µ–∑_NOUN', 0.0407133586704731),\n",
       " ('–Ω–æ–≤–æ—Å—Ç—å_NOUN', 0.030972125008702278),\n",
       " ('–≤—Ä–∞—Ç—å_INFN', 0.029972020536661148)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.most_similar(positive=[\"—Ä—ç–¥—Ä–∏–∫_NOUN\"], negative=[\"—Å—Ç–∞–ª–∫–µ—Ä_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–±–∞—Ä–±—Ä–∏–¥–∂_NOUN', 0.9998448491096497),\n",
       " ('—Ö—Ä–∏–ø–∞—Ç—ã–π_ADJF', 0.9998412132263184),\n",
       " ('—Å–Ω–æ–≤–∞_ADVB', 0.9997943043708801)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.most_similar(positive=[\"—Ä—ç–¥—Ä–∏–∫_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunatelly, the result of this model is better on this test than of any tried so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99977547"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.similarity(\"—Ä—ç–¥—Ä–∏–∫_NOUN\", \"–≥—É—Ç–∞_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99955827"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.similarity(\"—Ä—ç–¥—Ä–∏–∫_NOUN\", \"–∫–∏—Ä–∏–ª–ª_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996924"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.similarity(\"–∫–∏—Ä–∏–ª–ª_NOUN\", \"–≥—É—Ç–∞_NOUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, it cannot find the expected distinction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since both Dina and Martyshka have not visited Zona on their own, but Martyshka is definitelly more connected to it, it is interesting to check which of this terms would stand out on the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–¥–∏–Ω–∞_NOUN'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.doesnt_match(\"—Ä—ç–¥—Ä–∏–∫_NOUN –∑–æ–Ω–∞_NOUN –±–∞—Ä–±—Ä–∏–¥–∂_NOUN –∫–∏—Ä–∏–ª–ª_NOUN –º–∞—Ä—Ç—ã—à–∫–∞_NOUN –¥–∏–Ω–∞_NOUN\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–º–∞—Ä—Ç—ã—à–∫–∞_NOUN'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie5.wv.doesnt_match(\"—Ä—ç–¥—Ä–∏–∫_NOUN –∑–æ–Ω–∞_NOUN –±–∞—Ä–±—Ä–∏–¥–∂_NOUN –∫–∏—Ä–∏–ª–ª_NOUN –º–∞—Ä—Ç—ã—à–∫–∞_NOUN\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us introduce a number of fake words and increase the number of trainings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 09:09:36,849 : INFO : collecting all words and their counts\n",
      "2021-09-22 09:09:36,885 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-22 09:09:36,901 : INFO : collected 4182 word types from a corpus of 21762 raw words and 2531 sentences\n",
      "2021-09-22 09:09:36,901 : INFO : Creating a fresh vocabulary\n",
      "2021-09-22 09:09:36,918 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 4182 unique words (100.0%% of original 4182, drops 0)', 'datetime': '2021-09-22T09:09:36.918030', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-22 09:09:36,918 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 21762 word corpus (100.0%% of original 21762, drops 0)', 'datetime': '2021-09-22T09:09:36.918030', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-22 09:09:36,968 : INFO : deleting the raw counts dictionary of 4182 items\n",
      "2021-09-22 09:09:36,968 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2021-09-22 09:09:36,968 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 17128.94358646904 word corpus (78.7%% of prior 21762)', 'datetime': '2021-09-22T09:09:36.968714', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-09-22 09:09:37,035 : INFO : estimated required memory for 4182 words and 300 dimensions: 12127800 bytes\n",
      "2021-09-22 09:09:37,035 : INFO : resetting layer weights\n",
      "2021-09-22 09:09:37,035 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-09-22T09:09:37.035861', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-09-22 09:09:37,035 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4182 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=20 window=5 shrink_windows=True', 'datetime': '2021-09-22T09:09:37.035861', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-22 09:09:37,088 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,170 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,173 : INFO : EPOCH - 1 : training on 21762 raw words (17067 effective words) took 0.1s, 147758 effective words/s\n",
      "2021-09-22 09:09:37,227 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,277 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,297 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,298 : INFO : EPOCH - 2 : training on 21762 raw words (17164 effective words) took 0.1s, 144047 effective words/s\n",
      "2021-09-22 09:09:37,408 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,420 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,471 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,473 : INFO : EPOCH - 3 : training on 21762 raw words (17068 effective words) took 0.2s, 100792 effective words/s\n",
      "2021-09-22 09:09:37,513 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,562 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,568 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,569 : INFO : EPOCH - 4 : training on 21762 raw words (17105 effective words) took 0.1s, 186371 effective words/s\n",
      "2021-09-22 09:09:37,622 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,683 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,694 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,696 : INFO : EPOCH - 5 : training on 21762 raw words (17156 effective words) took 0.1s, 141777 effective words/s\n",
      "2021-09-22 09:09:37,754 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,806 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,820 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,822 : INFO : EPOCH - 6 : training on 21762 raw words (17175 effective words) took 0.1s, 145084 effective words/s\n",
      "2021-09-22 09:09:37,876 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:37,926 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:37,935 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:37,936 : INFO : EPOCH - 7 : training on 21762 raw words (17143 effective words) took 0.1s, 156191 effective words/s\n",
      "2021-09-22 09:09:37,994 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,027 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,051 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,052 : INFO : EPOCH - 8 : training on 21762 raw words (17101 effective words) took 0.1s, 155561 effective words/s\n",
      "2021-09-22 09:09:38,096 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,138 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,154 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,155 : INFO : EPOCH - 9 : training on 21762 raw words (17080 effective words) took 0.1s, 178142 effective words/s\n",
      "2021-09-22 09:09:38,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,218 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,238 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,238 : INFO : EPOCH - 10 : training on 21762 raw words (17148 effective words) took 0.1s, 203543 effective words/s\n",
      "2021-09-22 09:09:38,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,319 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,338 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,338 : INFO : EPOCH - 11 : training on 21762 raw words (17143 effective words) took 0.1s, 172634 effective words/s\n",
      "2021-09-22 09:09:38,388 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,439 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,439 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,439 : INFO : EPOCH - 12 : training on 21762 raw words (17115 effective words) took 0.1s, 187041 effective words/s\n",
      "2021-09-22 09:09:38,488 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,521 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,539 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,539 : INFO : EPOCH - 13 : training on 21762 raw words (17151 effective words) took 0.1s, 181897 effective words/s\n",
      "2021-09-22 09:09:38,588 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,621 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,639 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,655 : INFO : EPOCH - 14 : training on 21762 raw words (17110 effective words) took 0.1s, 166142 effective words/s\n",
      "2021-09-22 09:09:38,705 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,739 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,755 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,755 : INFO : EPOCH - 15 : training on 21762 raw words (17163 effective words) took 0.1s, 164509 effective words/s\n",
      "2021-09-22 09:09:38,802 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,839 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,855 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,855 : INFO : EPOCH - 16 : training on 21762 raw words (17034 effective words) took 0.1s, 179817 effective words/s\n",
      "2021-09-22 09:09:38,901 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:38,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:38,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:38,974 : INFO : EPOCH - 17 : training on 21762 raw words (17142 effective words) took 0.1s, 150759 effective words/s\n",
      "2021-09-22 09:09:39,023 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,056 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,073 : INFO : EPOCH - 18 : training on 21762 raw words (17136 effective words) took 0.1s, 175644 effective words/s\n",
      "2021-09-22 09:09:39,142 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,185 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,194 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,197 : INFO : EPOCH - 19 : training on 21762 raw words (17121 effective words) took 0.1s, 147364 effective words/s\n",
      "2021-09-22 09:09:39,255 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,300 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,322 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,323 : INFO : EPOCH - 20 : training on 21762 raw words (17091 effective words) took 0.1s, 142171 effective words/s\n",
      "2021-09-22 09:09:39,381 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,419 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,435 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,436 : INFO : EPOCH - 21 : training on 21762 raw words (17156 effective words) took 0.1s, 156669 effective words/s\n",
      "2021-09-22 09:09:39,495 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,569 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,573 : INFO : EPOCH - 22 : training on 21762 raw words (17179 effective words) took 0.1s, 130985 effective words/s\n",
      "2021-09-22 09:09:39,643 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,700 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,702 : INFO : EPOCH - 23 : training on 21762 raw words (17128 effective words) took 0.1s, 135536 effective words/s\n",
      "2021-09-22 09:09:39,744 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,796 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,805 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,807 : INFO : EPOCH - 24 : training on 21762 raw words (17118 effective words) took 0.1s, 168357 effective words/s\n",
      "2021-09-22 09:09:39,849 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,893 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:39,901 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:39,904 : INFO : EPOCH - 25 : training on 21762 raw words (17180 effective words) took 0.1s, 185671 effective words/s\n",
      "2021-09-22 09:09:39,950 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:39,986 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,004 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,005 : INFO : EPOCH - 26 : training on 21762 raw words (17109 effective words) took 0.1s, 173838 effective words/s\n",
      "2021-09-22 09:09:40,054 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,091 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,110 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,110 : INFO : EPOCH - 27 : training on 21762 raw words (17107 effective words) took 0.1s, 162713 effective words/s\n",
      "2021-09-22 09:09:40,142 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,191 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,191 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,191 : INFO : EPOCH - 28 : training on 21762 raw words (17115 effective words) took 0.1s, 209723 effective words/s\n",
      "2021-09-22 09:09:40,242 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,284 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,300 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,316 : INFO : EPOCH - 29 : training on 21762 raw words (17067 effective words) took 0.1s, 153269 effective words/s\n",
      "2021-09-22 09:09:40,375 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,422 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,423 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,423 : INFO : EPOCH - 30 : training on 21762 raw words (17156 effective words) took 0.1s, 159207 effective words/s\n",
      "2021-09-22 09:09:40,487 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,503 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,520 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,520 : INFO : EPOCH - 31 : training on 21762 raw words (17102 effective words) took 0.1s, 174782 effective words/s\n",
      "2021-09-22 09:09:40,567 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,636 : INFO : EPOCH - 32 : training on 21762 raw words (17188 effective words) took 0.1s, 169021 effective words/s\n",
      "2021-09-22 09:09:40,675 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,741 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,742 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,742 : INFO : EPOCH - 33 : training on 21762 raw words (17161 effective words) took 0.1s, 151520 effective words/s\n",
      "2021-09-22 09:09:40,808 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,859 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,877 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,877 : INFO : EPOCH - 34 : training on 21762 raw words (17116 effective words) took 0.1s, 132970 effective words/s\n",
      "2021-09-22 09:09:40,930 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-22 09:09:40,975 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-22 09:09:40,991 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-22 09:09:40,991 : INFO : EPOCH - 35 : training on 21762 raw words (17060 effective words) took 0.1s, 157179 effective words/s\n",
      "2021-09-22 09:09:40,991 : INFO : Word2Vec lifecycle event {'msg': 'training on 761670 raw words (599355 effective words) took 4.0s, 151621 effective words/s', 'datetime': '2021-09-22T09:09:40.991924', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-09-22 09:09:40,991 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4182, vector_size=300, alpha=0.025)', 'datetime': '2021-09-22T09:09:40.991924', 'gensim': '4.1.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model_strugackie6 = gensim.models.Word2Vec(data, vector_size=300, window=5, epochs = 35, negative = 20, ns_exponent = 0.75, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4182\n"
     ]
    }
   ],
   "source": [
    "print(len(model_strugackie6.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model_strugackie6.wv.key_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('—Ä—è—à–∫–∞_NOUN', 0.6155922412872314),\n",
       " ('–±–∞—Ä–±—Ä–∏–¥–∂_NOUN', 0.5065398216247559),\n",
       " ('—Ä—É–∫–∞_NOUN', 0.41529443860054016)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie6.wv.most_similar(positive=[\"—Ä—ç–¥—Ä–∏–∫_NOUN\"], negative=[\"—Å—Ç–∞–ª–∫–µ—Ä_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–±–∞—Ä–±—Ä–∏–¥–∂_NOUN', 0.9445749521255493),\n",
       " ('—Ö—Ä–∏–ø–∞—Ç—ã–π_ADJF', 0.9275789856910706),\n",
       " ('—Å–Ω–æ–≤–∞_ADVB', 0.8969085812568665)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie6.wv.most_similar(positive=[\"—Ä—ç–¥—Ä–∏–∫_NOUN\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75653267"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie6.wv.similarity(\"—Ä—ç–¥—Ä–∏–∫_NOUN\", \"–≥—É—Ç–∞_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4559571"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie6.wv.similarity(\"—Ä—ç–¥—Ä–∏–∫_NOUN\", \"–∫–∏—Ä–∏–ª–ª_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8581152"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie6.wv.similarity(\"–∫–∏—Ä–∏–ª–ª_NOUN\", \"–≥—É—Ç–∞_NOUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained model performs better than anyone tried before on each test. It also shows a difference in similarity coefficients for vectors —Ä—ç–¥—Ä–∏–∫_NOUN, –≥—É—Ç–∞_NOUN and –∫–∏—Ä–∏–ª–ª_NOUN. However, this difference is not expected. Probably, the initial hypothesis is flawed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–∑–æ–Ω–∞_NOUN'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strugackie6.wv.doesnt_match(\"—Ä—ç–¥—Ä–∏–∫_NOUN –∑–æ–Ω–∞_NOUN –±–∞—Ä–±—Ä–∏–¥–∂_NOUN –∫–∏—Ä–∏–ª–ª_NOUN –º–∞—Ä—Ç—ã—à–∫–∞_NOUN –¥–∏–Ω–∞_NOUN\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is even more logical that in the previous model, because in this case the model identifies an inanimate object as an odd one out among the animate entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Visualize the results of the training and testing (one plot or one graph), comment on the visualization -- 1 point**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if the final model is adequate, let us build a visualisation showing clusters of characters. The hypothesis behind this experiment is that vectors for Redrik, Guta, Martyshka, Kirill, Barbridzh, Artur and Dina will cluster in a way that will be consistent with the relationships bwtween those characters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['—Ä—ç–¥—Ä–∏–∫_NOUN', '–∫–∏—Ä–∏–ª–ª_NOUN', '–≥—É—Ç–∞_NOUN','–º–∞—Ä—Ç—ã—à–∫–∞_NOUN', '–±–∞—Ä–±—Ä–∏–¥–∂_NOUN', '–¥–∏–Ω–∞_NOUN', '–∞—Ä—Ç—É—Ä_NOUN']\n",
    "X = model_strugackie6.wv[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(coords[:, 0], coords[:, 1], color='red')\n",
    "plt.title('Words')\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(coords[i, 0], coords[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained visualisation is exceptionally successfull. As can be seen from the picture above, we have three clustrs each containing two terms. The central cluster brings together Matryshka and Guta, which is only reasonable, since they form a family in the novel. The right most cluster includes Redrik and Barbrigzh. This probably reflects the facts that both characters are stalkers and friends, and have visited Zona together many times. The third cluster comprises Dina and Artur who are siblings in the model. The fact that Kirill does not cluster with anyone clearly shows that his character is alienete to the world described."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Choose two sentences from the original text and substitute all the meaningful words with their closest neighbours from your word2vec model (1 point), do the agreement on the sentences with substitutions (1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had some problems understanding this task. It seemed a bit dull to me to specify inflection features of  words in a new sentence manually (at least I did not understand how it can be done automatically, since there is no place from where the code can take a set of agreement features for a semantically odd new sentence). So I decide for each new word obtained to specify a set of features available for the word it was taken instead of. For this I had to control for a new word to be of the same part of speech as the replaced word (this is why I had to preserve these features in the model). Moreover, I had to control for the features of the new and the old word not to clash. This is what expected, for example, if an obtained new noun is animate, while an old nominal term was inanimate. The feature of inanimacy can not be implemented on an animate noun in any case. The code below deliberately refuses to deal with a number of problems that arose during the work. First, it only seeks for the top five neighbors of the original term and then checks if any o them is of the same part of speech as the original token. If none of the found neighbors is of the same part of speech as the original word, the original term is kept. Otherwise, it would cost me a number of additional dull iterations of the same lines of code. Second, if the morphological analyser was not able to specify the inflection features of the original token correctly, the flawed set of features was transmitted to the new term without any correction. This is the case with the word \"–ø—Ä–∏—à–µ–ª–µ—Ü—ã_NOUN\". As can be seen from the results, for this word the morphological analyser failed to specify the plurality feature. For this reason, the agreement in the second sentence is incorrect. Since I'm not aware of any technique to verify agreemnt automatically, I decided not to do it manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = '–°–∞–º —Ñ–∞–∫—Ç –ü–æ—Å–µ—â–µ–Ω–∏—è —è–≤–ª—è–µ—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–º –æ—Ç–∫—Ä—ã—Ç–∏–µ–º –Ω–µ —Ç–æ–ª—å–∫–æ –∑–∞ –∏—Å—Ç–µ–∫—à–∏–µ —Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å –ª–µ—Ç –Ω–æ –∏ –∑–∞ –≤—Å–µ –≤—Ä–µ–º—è —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–∞. –ù–µ —Ç–∞–∫ —É–∂ –≤–∞–∂–Ω–æ –∫—Ç–æ –±—ã–ª–∏ —ç—Ç–∏ –ø—Ä–∏—à–µ–ª—å—Ü—ã'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sentences.split('.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–°–∞–º —Ñ–∞–∫—Ç –ü–æ—Å–µ—â–µ–Ω–∏—è —è–≤–ª—è–µ—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–º –æ—Ç–∫—Ä—ã—Ç–∏–µ–º –Ω–µ —Ç–æ–ª—å–∫–æ –∑–∞ –∏—Å—Ç–µ–∫—à–∏–µ —Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å –ª–µ—Ç –Ω–æ –∏ –∑–∞ –≤—Å–µ –≤—Ä–µ–º—è —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–∞', ' –ù–µ —Ç–∞–∫ —É–∂ –≤–∞–∂–Ω–æ –∫—Ç–æ –±—ã–ª–∏ —ç—Ç–∏ –ø—Ä–∏—à–µ–ª—å—Ü—ã']\n"
     ]
    }
   ],
   "source": [
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The results of the implementation of the code below are fully preserved to allow you to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–∞–º\n",
      "['sing', 'nomn']\n",
      "—Å–∞–º_ADJF\n",
      "[('–±—Ä–µ–¥–∏—Ç—å_INFN', 0.9499155282974243), ('—è_NPRO', 0.9416914582252502), ('–¥–∞–∂–µ_PRCL', 0.9415504932403564), ('—Å–µ—Ä–¥–∏—Ç–æ_ADVB', 0.9402171969413757), ('–∞_CONJ', 0.9317688345909119)]\n",
      "–±—Ä–µ–¥–∏—Ç—å_INFN\n",
      "INFN\n",
      "('—è_NPRO', 0.9416914582252502)\n",
      "—è_NPRO\n",
      "NPRO\n",
      "('–¥–∞–∂–µ_PRCL', 0.9415504932403564)\n",
      "('—Å–µ—Ä–¥–∏—Ç–æ_ADVB', 0.9402171969413757)\n",
      "('–∞_CONJ', 0.9317688345909119)\n",
      "—Å–∞–º HuRAAAAAA\n",
      "['sing', 'nomn']\n",
      "—Å–∞–º HURAAAAAAAAA\n",
      "THe enad\n",
      "—Ñ–∞–∫—Ç\n",
      "['nomn']\n",
      "—Ñ–∞–∫—Ç_NOUN\n",
      "[('—Å–æ–±–∏—Ä–∞—Ç—å—Å—è_INFN', 0.9989069104194641), ('–Ω–∞–∏–±–æ–ª–µ–µ_ADVB', 0.9987283945083618), ('–º–∞–º–∞_NOUN', 0.9985398054122925), ('–∑–∞–∫–ª–∞–¥—ã–≤–∞—Ç—å_INFN', 0.9985182881355286), ('—Ä–∞—Å–ø–æ—Ä—è–∂–∞—Ç—å—Å—è_INFN', 0.9985096454620361)]\n",
      "—Å–æ–±–∏—Ä–∞—Ç—å—Å—è_INFN\n",
      "INFN\n",
      "('–Ω–∞–∏–±–æ–ª–µ–µ_ADVB', 0.9987283945083618)\n",
      "–Ω–∞–∏–±–æ–ª–µ–µ_ADVB\n",
      "ADVB\n",
      "('–º–∞–º–∞_NOUN', 0.9985398054122925)\n",
      "–º–∞–º–∞_NOUN HuRAAAAAA\n",
      "['nomn']\n",
      "–º–∞–º–∞ HURAAAAAAAAA\n",
      "THe enad\n",
      "–ü–æ—Å–µ—â–µ–Ω–∏—è\n",
      "['gent']\n",
      "–ø–æ—Å–µ—â–µ–Ω–∏–µ_NOUN\n",
      "[('–≥–æ—Ä–æ–¥_NOUN', 0.9908337593078613), ('–º–æ–ª–æ–∫–æ_NOUN', 0.9907938838005066), ('–∑–∞–∫–∞–ø—ã–≤–∞—Ç—å_INFN', 0.9893375039100647), ('–∂—É—á–∫–æ–≤–ø–∞—É—á–æ–∫_NOUN', 0.988673210144043), ('–≤—Å–µ–≥–æ_ADJF', 0.9879376292228699)]\n",
      "–≥–æ—Ä–æ–¥_NOUN\n",
      "NOUN\n",
      "–≥–æ—Ä–æ–¥_NOUN HuRAAAAAA\n",
      "['gent']\n",
      "–≥–æ—Ä–æ–¥–∞ HURAAAAAAAAA\n",
      "THe enad\n",
      "—è–≤–ª—è–µ—Ç—Å—è\n",
      "['impf', '3per', 'pres', 'indc']\n",
      "—è–≤–ª—è—Ç—å—Å—è_VERB\n",
      "—è–≤–ª—è—Ç—å—Å—è_VERB HuRAAAAAA\n",
      "['impf', '3per', 'pres', 'indc']\n",
      "—è–≤–ª—è–µ—Ç—Å—è HURAAAAAAAAA\n",
      "THe enad\n",
      "–Ω–∞–∏–±–æ–ª–µ–µ\n",
      "[]\n",
      "THe enad\n",
      "–≤–∞–∂–Ω—ã–º\n",
      "['sing', 'ablt']\n",
      "–≤–∞–∂–Ω—ã–π_ADJF\n",
      "[('—É–≤–µ—Ä–µ–Ω–Ω—ã–π_ADJF', 0.9981768727302551), ('—É–∑–Ω–∞–≤–∞—Ç—å_INFN', 0.9981726408004761), ('–º–µ—Ä–µ—Ç—å_INFN', 0.9979825019836426), ('—Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å_INFN', 0.997803270816803), ('–æ—á–∫–∞—Ä–∏–∫_NOUN', 0.9974892735481262)]\n",
      "—É–≤–µ—Ä–µ–Ω–Ω—ã–π_ADJF\n",
      "ADJF\n",
      "—É–≤–µ—Ä–µ–Ω–Ω—ã–π_ADJF HuRAAAAAA\n",
      "['sing', 'ablt']\n",
      "—É–≤–µ—Ä–µ–Ω–Ω—ã–º HURAAAAAAAAA\n",
      "THe enad\n",
      "–æ—Ç–∫—Ä—ã—Ç–∏–µ–º\n",
      "['ablt']\n",
      "–æ—Ç–∫—Ä—ã—Ç–∏–µ_NOUN\n",
      "[('—Å–µ—Ä—å–µ–∑–Ω—ã–π_ADJF', 0.9986341595649719), ('–≤–µ—Ä–æ—è—Ç–Ω–æ_CONJ', 0.9986300468444824), ('–≤–ø–µ—Ä–≤—ã–µ_ADVB', 0.9970818161964417), ('–Ω–µ–ø–æ–Ω—è—Ç–Ω–æ_ADVB', 0.9967312216758728), ('–æ–¥–Ω–∞–∫–æ_CONJ', 0.9966637492179871)]\n",
      "—Å–µ—Ä—å–µ–∑–Ω—ã–π_ADJF\n",
      "ADJF\n",
      "('–≤–µ—Ä–æ—è—Ç–Ω–æ_CONJ', 0.9986300468444824)\n",
      "–≤–µ—Ä–æ—è—Ç–Ω–æ_CONJ\n",
      "CONJ\n",
      "('–≤–ø–µ—Ä–≤—ã–µ_ADVB', 0.9970818161964417)\n",
      "('–Ω–µ–ø–æ–Ω—è—Ç–Ω–æ_ADVB', 0.9967312216758728)\n",
      "('–æ–¥–Ω–∞–∫–æ_CONJ', 0.9966637492179871)\n",
      "–æ—Ç–∫—Ä—ã—Ç–∏–µ HuRAAAAAA\n",
      "['ablt']\n",
      "–æ—Ç–∫—Ä—ã—Ç–∏–µ–º HURAAAAAAAAA\n",
      "THe enad\n",
      "–Ω–µ\n",
      "[]\n",
      "THe enad\n",
      "—Ç–æ–ª—å–∫–æ\n",
      "[]\n",
      "THe enad\n",
      "–∑–∞\n",
      "[]\n",
      "THe enad\n",
      "–∏—Å—Ç–µ–∫—à–∏–µ\n",
      "['nomn']\n",
      "–∏—Å—Ç–µ–∫—à–∏–π_ADJF\n",
      "[('–≤–æ–ø—Ä–æ—Å_NOUN', 0.9975489377975464), ('—à–µ—Ä—Å—Ç–∫–∞_NOUN', 0.9975398778915405), ('–∑–∞–±—Ä–æ—Å–∏—Ç—å_INFN', 0.997526228427887), ('–º–µ—Ä—Ç–≤—ã–π_NOUN', 0.9974285960197449), ('–ø–ª–∞—Ç–∏—Ç—å_INFN', 0.9974076151847839)]\n",
      "–≤–æ–ø—Ä–æ—Å_NOUN\n",
      "NOUN\n",
      "('—à–µ—Ä—Å—Ç–∫–∞_NOUN', 0.9975398778915405)\n",
      "—à–µ—Ä—Å—Ç–∫–∞_NOUN\n",
      "NOUN\n",
      "('–∑–∞–±—Ä–æ—Å–∏—Ç—å_INFN', 0.997526228427887)\n",
      "('–º–µ—Ä—Ç–≤—ã–π_NOUN', 0.9974285960197449)\n",
      "('–ø–ª–∞—Ç–∏—Ç—å_INFN', 0.9974076151847839)\n",
      "–∏—Å—Ç–µ–∫—à–∏–π HuRAAAAAA\n",
      "['nomn']\n",
      "–∏—Å—Ç–µ–∫—à–∏–π HURAAAAAAAAA\n",
      "THe enad\n",
      "—Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å\n",
      "[]\n",
      "—Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å_NUMR\n",
      "[('–ø—Ä–æ—à–ª—ã–π_ADJF', 0.9978258609771729), ('–∫–æ–º–∏—Å—Å–∏—è_NOUN', 0.9972296357154846), ('–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç_NOUN', 0.9971507787704468), ('–æ–∫–ª–∞–¥_NOUN', 0.9971199035644531), ('—Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ_NOUN', 0.9968302249908447)]\n",
      "–ø—Ä–æ—à–ª—ã–π_ADJF\n",
      "ADJF\n",
      "('–∫–æ–º–∏—Å—Å–∏—è_NOUN', 0.9972296357154846)\n",
      "–∫–æ–º–∏—Å—Å–∏—è_NOUN\n",
      "NOUN\n",
      "('–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç_NOUN', 0.9971507787704468)\n",
      "('–æ–∫–ª–∞–¥_NOUN', 0.9971199035644531)\n",
      "('—Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ_NOUN', 0.9968302249908447)\n",
      "—Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å HuRAAAAAA\n",
      "[]\n",
      "—Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å HURAAAAAAAAA\n",
      "THe enad\n",
      "–ª–µ—Ç\n",
      "['gent']\n",
      "–≥–æ–¥_NOUN\n",
      "[('—á–∞—Å_NOUN', 0.9916371703147888), ('—Å—Ç–æ_NOUN', 0.9868099689483643), ('–¥–≤–∞–¥—Ü–∞—Ç—å_NUMR', 0.9860250949859619), ('–º–µ–∂–¥—É_PREP', 0.984811007976532), ('—É–ø–∞—Å—Ç–∏_INFN', 0.9844927191734314)]\n",
      "—á–∞—Å_NOUN\n",
      "NOUN\n",
      "—á–∞—Å_NOUN HuRAAAAAA\n",
      "['gent']\n",
      "—á–∞—Å–∞ HURAAAAAAAAA\n",
      "THe enad\n",
      "–Ω–æ\n",
      "[]\n",
      "THe enad\n",
      "–∏\n",
      "[]\n",
      "THe enad\n",
      "–∑–∞\n",
      "[]\n",
      "THe enad\n",
      "–≤—Å–µ\n",
      "[]\n",
      "THe enad\n",
      "–≤—Ä–µ–º—è\n",
      "['accs']\n",
      "–≤—Ä–µ–º—è_NOUN\n",
      "[('–Ω–µ–∫–æ—Ç–æ—Ä—ã–π_ADJF', 0.9309893846511841), ('–æ—Ç_PREP', 0.9240998029708862), ('—Å—Ç–æ—è—Ç—å_INFN', 0.9064339399337769), ('—Å—Ç–æ—Ä–æ–Ω–∞_NOUN', 0.9010434150695801), ('–ø—Ä–∏–≤—ã—á–∫–∞_NOUN', 0.8959077000617981)]\n",
      "–Ω–µ–∫–æ—Ç–æ—Ä—ã–π_ADJF\n",
      "ADJF\n",
      "('–æ—Ç_PREP', 0.9240998029708862)\n",
      "–æ—Ç_PREP\n",
      "PREP\n",
      "('—Å—Ç–æ—è—Ç—å_INFN', 0.9064339399337769)\n",
      "('—Å—Ç–æ—Ä–æ–Ω–∞_NOUN', 0.9010434150695801)\n",
      "—Å—Ç–æ—Ä–æ–Ω–∞_NOUN HuRAAAAAA\n",
      "['accs']\n",
      "—Å—Ç–æ—Ä–æ–Ω—É HURAAAAAAAAA\n",
      "THe enad\n",
      "—Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è\n",
      "['gent']\n",
      "—Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ_NOUN\n",
      "[('—Å—Ç–æ—Ä–æ–Ω–∫–∞_NOUN', 0.9981769323348999), ('—Å–±–æ–∫—É_ADVB', 0.9979127645492554), ('–∫–ª–∞–¥–±–∏—â–µ_NOUN', 0.9977166652679443), ('–¥–µ–ª–∏–∫–∞—Ç–Ω–æ_ADVB', 0.9976757168769836), ('–∑–µ–≤–∞—Ç—å_INFN', 0.9976224899291992)]\n",
      "—Å—Ç–æ—Ä–æ–Ω–∫–∞_NOUN\n",
      "NOUN\n",
      "—Å—Ç–æ—Ä–æ–Ω–∫–∞_NOUN HuRAAAAAA\n",
      "['gent']\n",
      "—Å—Ç–æ—Ä–æ–Ω–∫–∏ HURAAAAAAAAA\n",
      "THe enad\n",
      "—á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–∞\n",
      "['gent']\n",
      "—á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–æ_NOUN\n",
      "[('–æ–Ω–æ_NPRO', 0.9991969466209412), ('–±–æ–ª–µ–µ_ADVB', 0.9991881251335144), ('—à–∏—Ç–æ–∫—Ä—ã—Ç—å_INFN', 0.9990331530570984), ('–ø–∞—Ö–Ω—É—Ç—å_INFN', 0.9989485144615173), ('–∑–∞–ø–ª–∞–∫–∞—Ç—å_INFN', 0.9988934993743896)]\n",
      "–æ–Ω–æ_NPRO\n",
      "NPRO\n",
      "('–±–æ–ª–µ–µ_ADVB', 0.9991881251335144)\n",
      "–±–æ–ª–µ–µ_ADVB\n",
      "ADVB\n",
      "('—à–∏—Ç–æ–∫—Ä—ã—Ç—å_INFN', 0.9990331530570984)\n",
      "('–ø–∞—Ö–Ω—É—Ç—å_INFN', 0.9989485144615173)\n",
      "('–∑–∞–ø–ª–∞–∫–∞—Ç—å_INFN', 0.9988934993743896)\n",
      "—á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–æ HuRAAAAAA\n",
      "['gent']\n",
      "—á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–∞ HURAAAAAAAAA\n",
      "THe enad\n",
      "—Å–∞–º –º–∞–º–∞ –≥–æ—Ä–æ–¥–∞ —è–≤–ª—è–µ—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω–Ω—ã–º –æ—Ç–∫—Ä—ã—Ç–∏–µ–º –Ω–µ —Ç–æ–ª—å–∫–æ –∑–∞ –∏—Å—Ç–µ–∫—à–∏–π —Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å —á–∞—Å–∞ –Ω–æ –∏ –∑–∞ –≤—Å–µ —Å—Ç–æ—Ä–æ–Ω—É —Å—Ç–æ—Ä–æ–Ω–∫–∏ —á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–∞\n",
      "–ù–µ\n",
      "[]\n",
      "THe enad\n",
      "—Ç–∞–∫\n",
      "[]\n",
      "THe enad\n",
      "—É–∂\n",
      "[]\n",
      "THe enad\n",
      "–≤–∞–∂–Ω–æ\n",
      "['Prdx']\n",
      "THe enad\n",
      "–∫—Ç–æ\n",
      "['nomn']\n",
      "–∫—Ç–æ_NPRO\n",
      "[('—ç—Ç–æ_PRCL', 0.974466860294342), ('–µ—Å–ª–∏_CONJ', 0.9692867398262024), ('—á—Ç–æ_CONJ', 0.968459963798523), ('–∑–¥–µ—Å—å_ADVB', 0.9678905606269836), ('–±—ã—Ç—å_INFN', 0.9646321535110474)]\n",
      "—ç—Ç–æ_PRCL\n",
      "PRCL\n",
      "('–µ—Å–ª–∏_CONJ', 0.9692867398262024)\n",
      "–µ—Å–ª–∏_CONJ\n",
      "CONJ\n",
      "('—á—Ç–æ_CONJ', 0.968459963798523)\n",
      "('–∑–¥–µ—Å—å_ADVB', 0.9678905606269836)\n",
      "('–±—ã—Ç—å_INFN', 0.9646321535110474)\n",
      "–∫—Ç–æ HuRAAAAAA\n",
      "['nomn']\n",
      "–∫—Ç–æ HURAAAAAAAAA\n",
      "THe enad\n",
      "–±—ã–ª–∏\n",
      "['impf', 'past', 'indc']\n",
      "–±—ã—Ç—å_VERB\n",
      "–±—ã—Ç—å_VERB HuRAAAAAA\n",
      "['impf', 'past', 'indc']\n",
      "–±—ã–ª–∏ HURAAAAAAAAA\n",
      "THe enad\n",
      "—ç—Ç–∏\n",
      "['Subx', 'Apro', 'nomn']\n",
      "—ç—Ç–æ—Ç_ADJF\n",
      "[('–∫–∞–∂–¥—ã–π_ADJF', 0.9606833457946777), ('–ø–æ—Å–ª–µ–¥–Ω–∏–π_ADJF', 0.953863799571991), ('–ø–æ—Å–µ—â–µ–Ω–∏–µ_NOUN', 0.9505617618560791), ('–∫–≤–∞—Ä—Ç–∞–ª_NOUN', 0.9475405812263489), ('—á—É–º–Ω–∞—è_ADJF', 0.9469196796417236)]\n",
      "–∫–∞–∂–¥—ã–π_ADJF\n",
      "ADJF\n",
      "–∫–∞–∂–¥—ã–π_ADJF HuRAAAAAA\n",
      "['Subx', 'Apro', 'nomn']\n",
      "–∫–∞–∂–¥—ã–π HURAAAAAAAAA\n",
      "THe enad\n",
      "–ø—Ä–∏—à–µ–ª—å—Ü—ã\n",
      "['nomn']\n",
      "–ø—Ä–∏—à–µ–ª–µ—Ü_NOUN\n",
      "[('–∫–∞–∫–∞—è—Ç–æ_PRTS', 0.9992594122886658), ('–∫–æ—Å—Ç—å_NOUN', 0.9989877343177795), ('—Å—Ç—Ä–∞—à–Ω–æ_ADVB', 0.998884916305542), ('–ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å_INFN', 0.9988200664520264), ('—Å—É—Ç—å_VERB', 0.9987511038780212)]\n",
      "–∫–∞–∫–∞—è—Ç–æ_PRTS\n",
      "PRTS\n",
      "('–∫–æ—Å—Ç—å_NOUN', 0.9989877343177795)\n",
      "–∫–æ—Å—Ç—å_NOUN\n",
      "NOUN\n",
      "–∫–æ—Å—Ç—å_NOUN HuRAAAAAA\n",
      "['nomn']\n",
      "–∫–æ—Å—Ç—å HURAAAAAAAAA\n",
      "THe enad\n",
      "–ù–µ —Ç–∞–∫ —É–∂ –≤–∞–∂–Ω–æ –∫—Ç–æ –±—ã–ª–∏ –∫–∞–∂–¥—ã–π –∫–æ—Å—Ç—å\n"
     ]
    }
   ],
   "source": [
    "new_sents = []\n",
    "stops = ['PREP', 'CONJ', 'PRCL', 'INTJ', 'ADVB']\n",
    "for l in lines:\n",
    "    new_bag = []\n",
    "    words = l.split()\n",
    "    for w in words:\n",
    "        print(w)\n",
    "        ana = morph.parse(w)[0].tag\n",
    "        feats = str(ana).split(',')\n",
    "        if len(feats[0]) > 4:\n",
    "            feats[0] = feats[0].split(' ')[0]\n",
    "        feats2 = feats[1:]\n",
    "        feats3 = []\n",
    "        for f in feats2:\n",
    "            if len(f) > 4:\n",
    "                continue\n",
    "            if f == \"anim\" or f == \"inan\":\n",
    "                continue\n",
    "            else:\n",
    "                feats3.append(f)\n",
    "        print(feats3)\n",
    "        if feats[0] in stops:\n",
    "            x  = w\n",
    "        else:\n",
    "            lemma = m.lemmatize(w)[0]\n",
    "            lemma_1 = lemma + '_' + str(feats[0])\n",
    "            print(lemma_1)\n",
    "            if lemma_1 in list(model_strugackie6.wv.key_to_index.keys()):\n",
    "                    substitutes = model_strugackie6.wv.most_similar(positive=[lemma_1], topn=5)\n",
    "                    print(substitutes)\n",
    "                    substitute = substitutes[0]\n",
    "                    new_lemma = substitute[0] \n",
    "                    print(new_lemma)\n",
    "                    POS_new_lemma = new_lemma.split('_')[1]\n",
    "                    print(POS_new_lemma)\n",
    "                    if POS_new_lemma == str(feats[0]):\n",
    "                        act_substitute = new_lemma\n",
    "                    else:\n",
    "                        substitute1 =  substitutes[1]\n",
    "                        print(substitute1)\n",
    "                        new_lemma1 = substitute1[0]\n",
    "                        print(new_lemma1)\n",
    "                        POS_new_lemma1 = new_lemma1.split('_')[1]\n",
    "                        print(POS_new_lemma1)\n",
    "                        if POS_new_lemma1 == str(feats[0]):\n",
    "                            act_substitute = new_lemma1\n",
    "                        else:\n",
    "                            substitute2 = substitutes[2]\n",
    "                            print(substitute2)\n",
    "                            new_lemma2 = substitute2[0]\n",
    "                            POS_new_lemma2 = new_lemma2.split('_')[1]\n",
    "                            if POS_new_lemma2 == str(feats[0]):\n",
    "                                act_substitute = new_lemma2 \n",
    "                            else:\n",
    "                                substitute3 = substitutes[3]\n",
    "                                print(substitute3)\n",
    "                                new_lemma3 = substitute3[0]\n",
    "                                POS_new_lemma3 = new_lemma3.split('_')[1]\n",
    "                                if POS_new_lemma3 == str(feats[0]):\n",
    "                                    act_substitute = new_lemma3\n",
    "                                else:\n",
    "                                    substitute4 = substitutes[4]\n",
    "                                    print(substitute4)\n",
    "                                    new_lemma4 = substitute4[0]\n",
    "                                    POS_new_lemma4 = new_lemma4.split('_')[1]\n",
    "                                    if POS_new_lemma3 == str(feats[0]):\n",
    "                                        act_substitute = new_lemma4 \n",
    "                                    else:\n",
    "                                        act_substitute = lemma\n",
    "            else:\n",
    "                act_substitute = lemma_1\n",
    "            print(act_substitute, \"HuRAAAAAA\")\n",
    "            i = 0\n",
    "            x =  act_substitute.split('_')[0]\n",
    "            print(feats3)\n",
    "            while i < len(feats3):\n",
    "                an = morph.parse(x)[0]\n",
    "                fea = str(feats3[i])\n",
    "                new_form = an.inflect({fea}).word\n",
    "                x = new_form\n",
    "                i = i + 1\n",
    "            print(x, \"HURAAAAAAAAA\")\n",
    "        print(\"THe enad\")\n",
    "        new_bag.append(x)\n",
    "    new_sent = ' '.join(new_bag)\n",
    "    print(new_sent)\n",
    "    new_sents.append(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['—Å–∞–º –º–∞–º–∞ –≥–æ—Ä–æ–¥–∞ —è–≤–ª—è–µ—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω–Ω—ã–º –æ—Ç–∫—Ä—ã—Ç–∏–µ–º –Ω–µ —Ç–æ–ª—å–∫–æ –∑–∞ –∏—Å—Ç–µ–∫—à–∏–π —Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å —á–∞—Å–∞ –Ω–æ –∏ –∑–∞ –≤—Å–µ —Å—Ç–æ—Ä–æ–Ω—É —Å—Ç–æ—Ä–æ–Ω–∫–∏ —á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–∞', '–ù–µ —Ç–∞–∫ —É–∂ –≤–∞–∂–Ω–æ –∫—Ç–æ –±—ã–ª–∏ –∫–∞–∂–¥—ã–π –∫–æ—Å—Ç—å']\n"
     ]
    }
   ],
   "source": [
    "print(new_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
